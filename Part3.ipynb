{
  "cells": [
    {
      "metadata": {
        "_uuid": "3a0763d811fbe757713bd53da42f092a94b7d7ae"
      },
      "cell_type": "markdown",
      "source": "## **Αναγνώριση Προτύπων - 3η Εργαστηριακή Άσκηση** ##\n\n## Αναγνώριση Είδους και Εξαγωγή Συναισθήματος από Μουσική ##"
    },
    {
      "metadata": {
        "_uuid": "7899dfd5eb0164340ae5aa9b9cfb094366dc3b9e"
      },
      "cell_type": "markdown",
      "source": "* Χρυσούλα Κοσμά - 03114025\n* Λεωνίδας Αβδελάς - 03113182\n\n9ο Εξάμηνο ΣΗΜΜΥ ΕΜΠ"
    },
    {
      "metadata": {
        "_uuid": "34a9b398e034db054c4a54823916b876eb7f1ed3"
      },
      "cell_type": "markdown",
      "source": "Ακολουθούν τα **βήματα του κύριου μέρους (βήματα 10-11)** του 3ου Εργαστηρίου.\n\nΑρχικά, κάνουμε import ορισμένες από τις βιβλιοθήκες που είναι απαραίτητες για την εκτέλεση των βημάτων της εργασίας."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "52aab40de905fd887673b4ba1cbba51778671bcd"
      },
      "cell_type": "code",
      "source": "import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gzip\nimport matplotlib.pyplot as plt\nimport librosa\n\nfrom librosa import display\nfrom librosa import beat",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7bf609a64630286d7f10fcb985a69ebd2e0871de"
      },
      "cell_type": "code",
      "source": "print('Files in multitask_dataset folder')\nprint(os.listdir(\"../input/data/data/multitask_dataset\"))\npath = \"../input/data/data/multitask_dataset/train_labels.txt\"\nf = open(path, 'r')\nfile_contents = f.read()\nprint('\\nTrain_labels.txt in multitask_dataset')\nprint(file_contents)\nf.close()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Files in multitask_dataset folder\n['train', 'test', 'train_labels.txt']\n\nTrain_labels.txt in multitask_dataset\nId,valence,energy,danceability\n5823,0.578,0.973,0.873\n6276,0.839,0.782,0.655\n9505,0.587,0.956,0.204\n5042,0.222,0.226,0.189\n6073,0.576,0.842,0.869\n2021,0.595,0.769,0.801\n3361,0.557,0.964,0.571\n8133,0.364,0.63,0.345\n9811,0.89,0.442,0.63\n1755,0.716,0.514,0.592\n8424,0.699,0.949,0.522\n8421,0.188,0.689,0.547\n7737,0.902,0.605,0.591\n6807,0.866,0.633,0.646\n1866,0.743,0.212,0.465\n3979,0.779,0.798,0.807\n3932,0.0702,0.552,0.485\n8112,0.355,0.984,0.364\n2864,0.858,0.638,0.834\n7209,0.0859,0.216,0.266\n2935,0.759,0.665,0.95\n7892,0.795,0.387,0.631\n6355,0.561,0.585,0.621\n3318,0.173,0.832,0.792\n7134,0.784,0.806,0.47\n6201,0.454,0.622,0.467\n2065,0.821,0.661,0.854\n4734,0.29,0.182,0.25\n8854,0.561,0.961,0.403\n8228,0.561,0.772,0.582\n2717,0.911,0.72,0.845\n2044,0.846,0.825,0.819\n7531,0.854,0.677,0.483\n7014,0.541,0.908,0.472\n8190,0.257,0.727,0.555\n1553,0.723,0.557,0.423\n8578,0.491,0.712,0.29\n5861,0.848,0.824,0.798\n5524,0.0687,0.0975,0.0906\n8045,0.836,0.87,0.514\n8705,0.252,0.948,0.335\n8046,0.815,0.882,0.495\n2094,0.765,0.725,0.814\n8119,0.538,0.887,0.355\n6402,0.213,0.357,0.387\n7743,0.765,0.829,0.52\n2850,0.288,0.687,0.808\n6595,0.878,0.812,0.438\n5394,0.558,0.597,0.778\n2226,0.0766,0.538,0.361\n4795,0.33,0.231,0.428\n5603,0.629,0.819,0.388\n7997,0.352,0.0413,0.513\n8973,0.141,0.965,0.253\n3590,0.645,0.819,0.636\n3257,0.705,0.859,0.512\n7930,0.767,0.467,0.699\n2402,0.432,0.442,0.66\n8977,0.237,0.94,0.424\n8727,0.147,0.902,0.315\n8936,0.151,0.956,0.431\n2619,0.611,0.747,0.849\n2259,0.273,0.711,0.685\n9014,0.653,0.935,0.556\n5591,0.844,0.823,0.659\n8926,0.559,0.978,0.437\n5273,0.864,0.916,0.698\n5049,0.602,0.271,0.595\n3050,0.747,0.588,0.592\n5204,0.811,0.672,0.626\n7663,0.391,0.338,0.396\n9666,0.517,0.912,0.6\n7416,0.53,0.883,0.492\n3767,0.9,0.636,0.842\n7018,0.59,0.409,0.747\n5561,0.891,0.704,0.736\n6893,0.694,0.839,0.598\n5253,0.716,0.453,0.644\n9004,0.362,0.94,0.366\n2811,0.307,0.544,0.756\n5694,0.827,0.879,0.675\n6642,0.362,0.458,0.684\n3563,0.852,0.897,0.638\n8574,0.392,0.872,0.58\n1804,0.618,0.0784,0.681\n2322,0.152,0.911,0.624\n7715,0.963,0.796,0.344\n2861,0.417,0.291,0.546\n8865,0.299,0.952,0.493\n5950,0.463,0.655,0.813\n5096,0.132,0.124,0.282\n8041,0.406,0.424,0.407\n5538,0.0684,0.17,0.163\n6161,0.759,0.665,0.95\n6411,0.318,0.222,0.708\n7945,0.682,0.328,0.347\n3778,0.835,0.915,0.737\n4695,0.364,0.178,0.594\n3292,0.27,0.605,0.656\n6471,0.743,0.59,0.533\n1980,0.592,0.839,0.567\n7290,0.352,0.708,0.592\n4327,0.232,0.993,0.607\n8274,0.44,0.716,0.537\n5722,0.798,0.92,0.693\n5197,0.609,0.635,0.497\n2050,0.54,0.818,0.882\n4742,0.107,0.0923,0.342\n4723,0.527,0.405,0.478\n7520,0.321,0.592,0.761\n4569,0.619,0.309,0.478\n3056,0.591,0.339,0.434\n3071,0.478,0.643,0.746\n6125,0.458,0.826,0.454\n7987,0.857,0.573,0.586\n3963,0.148,0.479,0.913\n9210,0.329,0.989,0.393\n3728,0.922,0.855,0.652\n5654,0.539,0.515,0.772\n3455,0.901,0.782,0.729\n8155,0.733,0.878,0.492\n6006,0.493,0.493,0.64\n7683,0.958,0.556,0.88\n5781,0.816,0.546,0.693\n4810,0.153,0.136,0.208\n5196,0.597,0.292,0.364\n8808,0.0765,0.978,0.474\n1418,0.338,0.306,0.547\n5710,0.608,0.832,0.709\n4373,0.928,0.668,0.796\n2349,0.929,0.947,0.802\n6700,0.183,0.43,0.383\n7032,0.481,0.905,0.533\n8990,0.535,0.887,0.317\n9710,0.558,0.875,0.284\n4800,0.47,0.338,0.574\n6017,0.595,0.627,0.67\n5962,0.91,0.744,0.866\n8204,0.778,0.881,0.628\n5475,0.204,0.823,0.706\n5183,0.641,0.301,0.637\n2655,0.0732,0.85,0.47\n8248,0.536,0.917,0.453\n4076,0.729,0.607,0.947\n6033,0.773,0.769,0.677\n6957,0.318,0.474,0.658\n2200,0.715,0.923,0.666\n6941,0.782,0.85,0.606\n5762,0.711,0.589,0.346\n1631,0.671,0.427,0.638\n4725,0.672,0.188,0.454\n1175,0.48,0.175,0.587\n4281,0.965,0.935,0.677\n4190,0.856,0.63,0.695\n9314,0.233,0.871,0.4\n5175,0.609,0.517,0.663\n7056,0.621,0.538,0.412\n6182,0.805,0.923,0.488\n4503,0.873,0.418,0.65\n6427,0.758,0.65,0.664\n7358,0.721,0.977,0.343\n6852,0.873,0.877,0.387\n8740,0.243,0.995,0.426\n4754,0.104,0.0967,0.331\n6501,0.148,0.336,0.428\n8375,0.967,0.912,0.518\n4451,0.305,0.369,0.312\n9598,0.257,0.986,0.44\n7126,0.497,0.434,0.506\n9334,0.0936,0.974,0.168\n3420,0.65,0.815,0.667\n7506,0.758,0.583,0.652\n1641,0.54,0.18,0.729\n3276,0.0848,0.836,0.568\n1812,0.839,0.89,0.754\n7750,0.8,0.596,0.469\n4973,0.643,0.269,0.627\n9848,0.659,0.884,0.442\n6855,0.74,0.911,0.493\n5708,0.102,0.768,0.645\n2397,0.657,0.889,0.675\n8691,0.203,0.892,0.388\n2838,0.358,0.695,0.908\n9069,0.23,0.744,0.277\n6965,0.606,0.696,0.576\n5641,0.812,0.806,0.74\n9113,0.216,0.857,0.358\n4034,0.581,0.899,0.625\n5604,0.373,0.431,0.283\n6929,0.5,0.76,0.583\n3057,0.567,0.355,0.468\n1491,0.644,0.507,0.488\n4022,0.804,0.785,0.775\n4450,0.56,0.726,0.495\n1783,0.661,0.148,0.738\n7365,0.818,0.833,0.461\n9378,0.821,0.953,0.506\n9540,0.111,0.972,0.411\n4275,0.516,0.592,0.765\n8836,0.17,0.901,0.244\n2821,0.759,0.665,0.95\n9437,0.851,0.968,0.51\n6111,0.415,0.981,0.355\n2351,0.727,0.884,0.83\n4550,0.71,0.606,0.837\n7774,0.41,0.435,0.688\n3869,0.818,0.764,0.658\n4110,0.736,0.492,0.671\n7931,0.946,0.83,0.417\n1782,0.738,0.256,0.667\n1399,0.627,0.426,0.673\n8872,0.359,0.979,0.306\n2176,0.12,0.0978,0.585\n1066,0.177,0.113,0.264\n8703,0.433,0.845,0.632\n5271,0.797,0.689,0.638\n6472,0.302,0.39,0.675\n4012,0.618,0.618,0.865\n1963,0.788,0.716,0.894\n6248,0.456,0.719,0.551\n7030,0.109,0.473,0.373\n4737,0.285,0.307,0.281\n9681,0.671,0.89,0.607\n3687,0.843,0.792,0.68\n8020,0.446,0.962,0.371\n5880,0.767,0.677,0.731\n5803,0.856,0.654,0.92\n6779,0.456,0.767,0.501\n3109,0.619,0.786,0.651\n1328,0.489,0.456,0.592\n9603,0.885,0.877,0.603\n1849,0.881,0.658,0.77\n4604,0.383,0.553,0.537\n6738,0.498,0.775,0.501\n9385,0.343,0.98,0.183\n4027,0.473,0.852,0.634\n6232,0.236,0.67,0.6\n6108,0.788,0.637,0.796\n2968,0.0707,0.773,0.566\n5325,0.689,0.486,0.701\n2692,0.593,0.513,0.813\n4579,0.147,0.176,0.405\n3424,0.613,0.976,0.53\n6819,0.707,0.832,0.508\n3805,0.922,0.713,0.682\n5767,0.834,0.631,0.538\n9744,0.302,0.588,0.479\n3569,0.954,0.925,0.722\n1716,0.973,0.562,0.717\n1684,0.703,0.244,0.684\n1693,0.513,0.365,0.583\n4095,0.918,0.739,0.818\n7178,0.312,0.704,0.23\n2640,0.873,0.829,0.803\n2911,0.629,0.859,0.922\n6915,0.245,0.321,0.303\n9730,0.477,0.865,0.372\n6850,0.398,0.89,0.222\n4845,0.626,0.321,0.583\n4822,0.0454,0.0922,0.227\n7822,0.942,0.849,0.482\n2463,0.543,0.723,0.706\n5495,0.624,0.366,0.608\n7994,0.344,0.19,0.651\n2054,0.517,0.93,0.782\n8205,0.397,0.871,0.464\n5351,0.239,0.485,0.814\n7500,0.968,0.821,0.581\n4268,0.788,0.798,0.734\n5973,0.358,0.857,0.702\n4030,0.882,0.719,0.612\n2319,0.353,0.793,0.602\n5344,0.673,0.696,0.388\n4713,0.17,0.648,0.47\n8268,0.506,0.579,0.551\n5997,0.486,0.319,0.703\n8643,0.114,0.403,0.559\n1048,0.116,0.0667,0.225\n1994,0.442,0.681,0.842\n4248,0.809,0.49,0.675\n9207,0.207,0.953,0.475\n1416,0.229,0.0175,0.505\n1116,0.609,0.691,0.48\n7634,0.49,0.575,0.551\n4399,0.151,0.0519,0.312\n8885,0.172,0.995,0.196\n3172,0.0393,0.0228,0.17\n6542,0.572,0.307,0.433\n9552,0.681,0.72,0.744\n8663,0.389,0.649,0.563\n4634,0.764,0.359,0.399\n9033,0.502,0.909,0.458\n8714,0.368,0.914,0.524\n6513,0.949,0.495,0.585\n8385,0.627,0.691,0.59\n3295,0.0648,0.708,0.594\n8662,0.167,0.875,0.308\n7492,0.429,0.196,0.307\n1305,0.887,0.483,0.815\n1468,0.527,0.216,0.545\n3327,0.373,0.728,0.654\n4367,0.865,0.521,0.453\n6678,0.734,0.388,0.413\n7330,0.258,0.906,0.256\n5764,0.591,0.485,0.583\n1635,0.717,0.352,0.681\n1801,0.836,0.137,0.808\n4020,0.631,0.74,0.711\n9317,0.348,0.742,0.362\n2119,0.215,0.577,0.593\n8674,0.136,0.978,0.388\n7943,0.24,0.177,0.551\n7532,0.802,0.805,0.59\n1964,0.599,0.272,0.754\n2930,0.681,0.561,0.807\n9285,0.254,0.989,0.439\n5367,0.0925,0.774,0.718\n2824,0.741,0.73,0.535\n4803,0.241,0.0887,0.309\n6241,0.104,0.767,0.736\n2639,0.0748,0.662,0.656\n2272,0.439,0.503,0.773\n6265,0.342,0.221,0.513\n6639,0.336,0.367,0.585\n4357,0.156,0.92,0.552\n5917,0.36,0.752,0.596\n5511,0.545,0.749,0.791\n9580,0.174,0.996,0.586\n9202,0.124,0.96,0.448\n2213,0.315,0.906,0.708\n3660,0.965,0.93,0.737\n8755,0.244,0.858,0.518\n7381,0.255,0.761,0.383\n3905,0.823,0.85,0.665\n3227,0.269,0.681,0.619\n2073,0.67,0.723,0.939\n9140,0.271,0.929,0.257\n3625,0.623,0.866,0.701\n9790,0.735,0.872,0.586\n8803,0.494,0.908,0.429\n7118,0.513,0.265,0.503\n2190,0.365,0.486,0.567\n1081,0.321,0.211,0.55\n9714,0.814,0.849,0.671\n8565,0.234,0.695,0.32\n6186,0.216,0.656,0.576\n8887,0.151,0.905,0.258\n5983,0.404,0.439,0.457\n9833,0.359,0.917,0.557\n8918,0.547,0.946,0.427\n8759,0.373,0.954,0.447\n9635,0.552,0.717,0.595\n6808,0.708,0.703,0.619\n9163,0.191,0.886,0.27\n6457,0.329,0.845,0.519\n4214,0.0443,0.444,0.55\n6212,0.619,0.866,0.578\n7170,0.38,0.481,0.367\n8091,0.569,0.864,0.26\n8480,0.789,0.86,0.775\n7286,0.334,0.224,0.715\n4899,0.658,0.293,0.631\n4226,0.683,0.732,0.629\n4649,0.814,0.643,0.672\n8018,0.716,0.51,0.633\n2758,0.403,0.731,0.516\n3111,0.0479,0.198,0.104\n4092,0.905,0.619,0.833\n6702,0.779,0.588,0.429\n6118,0.581,0.485,0.724\n2791,0.47,0.421,0.734\n5965,0.794,0.861,0.868\n5018,0.264,0.258,0.516\n6048,0.36,0.752,0.596\n6464,0.392,0.525,0.69\n1012,0.0564,0.0319,0.234\n7876,0.647,0.363,0.599\n6250,0.403,0.734,0.822\n9039,0.327,0.255,0.593\n1713,0.962,0.634,0.624\n3812,0.836,0.879,0.724\n9365,0.633,0.918,0.512\n6378,0.829,0.863,0.693\n9668,0.896,0.968,0.692\n5097,0.682,0.252,0.674\n2704,0.35,0.658,0.734\n5034,0.355,0.753,0.515\n1190,0.705,0.532,0.624\n6803,0.706,0.935,0.488\n4578,0.302,0.123,0.499\n4410,0.801,0.14,0.702\n8498,0.378,0.522,0.771\n6237,0.802,0.571,0.837\n6589,0.781,0.686,0.44\n1193,0.706,0.26,0.834\n7998,0.831,0.446,0.731\n9820,0.814,0.889,0.242\n4502,0.789,0.549,0.731\n2103,0.656,0.615,0.795\n7624,0.78,0.656,0.635\n8751,0.189,0.966,0.47\n3063,0.473,0.223,0.527\n2813,0.389,0.95,0.766\n9761,0.963,0.788,0.765\n1359,0.905,0.633,0.699\n4176,0.806,0.487,0.92\n2590,0.237,0.386,0.816\n7159,0.238,0.318,0.336\n1981,0.432,0.539,0.7\n4769,0.403,0.261,0.421\n2989,0.877,0.858,0.691\n3245,0.0436,0.949,0.513\n8453,0.867,0.838,0.568\n5931,0.522,0.791,0.53\n7071,0.554,0.865,0.364\n3369,0.302,0.72,0.673\n3987,0.65,0.922,0.734\n4124,0.7,0.489,0.84\n9101,0.207,0.986,0.36\n8610,0.0509,0.245,0.217\n9201,0.538,0.971,0.569\n2066,0.628,0.658,0.716\n3091,0.23,0.696,0.536\n8031,0.912,0.926,0.406\n6216,0.334,0.868,0.738\n7899,0.966,0.749,0.351\n9521,0.45,0.989,0.139\n6946,0.489,0.965,0.299\n2141,0.702,0.699,0.888\n9632,0.316,0.804,0.422\n2958,0.261,0.649,0.601\n8492,0.0867,0.495,0.707\n1370,0.726,0.262,0.618\n3487,0.264,0.733,0.502\n8490,0.283,0.487,0.598\n5569,0.828,0.92,0.547\n4074,0.873,0.539,0.909\n5598,0.593,0.776,0.481\n8993,0.517,0.989,0.444\n4492,0.423,0.412,0.719\n5384,0.247,0.269,0.622\n6805,0.474,0.895,0.671\n3678,0.95,0.979,0.662\n2287,0.924,0.924,0.707\n4661,0.748,0.389,0.559\n4611,0.731,0.41,0.515\n1738,0.732,0.414,0.401\n3100,0.0357,0.834,0.652\n4048,0.185,0.708,0.647\n4838,0.872,0.34,0.581\n3266,0.193,0.931,0.665\n7713,0.961,0.691,0.69\n4655,0.573,0.261,0.631\n8023,0.731,0.93,0.398\n8799,0.353,0.823,0.467\n1976,0.702,0.682,0.723\n8935,0.267,0.905,0.462\n7537,0.333,0.179,0.332\n1484,0.516,0.152,0.478\n8084,0.267,0.498,0.272\n3570,0.823,0.943,0.68\n1638,0.627,0.248,0.677\n1171,0.772,0.747,0.597\n3211,0.213,0.753,0.404\n9116,0.0639,0.964,0.516\n8833,0.274,0.392,0.52\n6334,0.453,0.397,0.377\n3024,0.766,0.505,0.481\n4430,0.597,0.573,0.485\n9390,0.478,0.951,0.532\n7891,0.951,0.522,0.589\n7015,0.706,0.936,0.335\n6571,0.246,0.353,0.588\n3066,0.322,0.374,0.754\n1118,0.813,0.703,0.653\n3412,0.765,0.878,0.573\n9834,0.837,0.55,0.579\n2539,0.0803,0.93,0.698\n8709,0.568,0.807,0.648\n5912,0.463,0.655,0.813\n3108,0.963,0.988,0.688\n1436,0.952,0.682,0.696\n1997,0.789,0.605,0.674\n4680,0.765,0.511,0.594\n4691,0.271,0.202,0.354\n4379,0.111,0.197,0.465\n1125,0.654,0.697,0.525\n6254,0.239,0.485,0.67\n7439,0.966,0.701,0.52\n6451,0.885,0.819,0.617\n8347,0.386,0.713,0.806\n6005,0.838,0.896,0.634\n2108,0.44,0.812,0.464\n2769,0.454,0.497,0.68\n6526,0.888,0.763,0.57\n2784,0.449,0.587,0.631\n2433,0.937,0.699,0.812\n1241,0.925,0.828,0.642\n5167,0.806,0.49,0.34\n1444,0.918,0.345,0.638\n1384,0.709,0.527,0.708\n9532,0.4,0.989,0.436\n6307,0.221,0.266,0.529\n6395,0.689,0.857,0.563\n3316,0.378,0.911,0.542\n1430,0.664,0.34,0.742\n8430,0.361,0.791,0.567\n9723,0.448,0.876,0.438\n1088,0.3,0.536,0.643\n7429,0.702,0.586,0.552\n1213,0.964,0.503,0.573\n8021,0.884,0.877,0.426\n3841,0.972,0.488,0.884\n9542,0.513,0.946,0.206\n2251,0.615,0.887,0.712\n8891,0.385,0.953,0.248\n2118,0.371,0.819,0.507\n6023,0.711,0.909,0.561\n1303,0.911,0.405,0.629\n6728,0.84,0.882,0.514\n6242,0.49,0.712,0.688\n5125,0.156,0.163,0.33\n1732,0.888,0.517,0.624\n3152,0.536,0.84,0.549\n5420,0.335,0.353,0.252\n9794,0.468,0.845,0.371\n1130,0.687,0.413,0.833\n3001,0.571,0.727,0.541\n6178,0.57,0.553,0.675\n3022,0.178,0.248,0.748\n3113,0.939,0.944,0.65\n3028,0.91,0.754,0.679\n8258,0.462,0.717,0.62\n5260,0.225,0.661,0.697\n3662,0.427,0.977,0.625\n6385,0.857,0.833,0.613\n6193,0.448,0.622,0.859\n4301,0.874,0.86,0.624\n9733,0.789,0.627,0.66\n1471,0.866,0.535,0.532\n4613,0.368,0.149,0.508\n1308,0.922,0.804,0.489\n1905,0.649,0.545,0.602\n3544,0.0768,0.716,0.601\n7458,0.198,0.176,0.218\n6332,0.756,0.443,0.52\n1100,0.812,0.938,0.701\n6476,0.3,0.142,0.607\n7969,0.697,0.731,0.354\n2579,0.32,0.657,0.671\n1097,0.969,0.874,0.539\n5599,0.928,0.689,0.687\n5187,0.967,0.53,0.618\n4065,0.777,0.742,0.809\n7420,0.469,0.3,0.555\n9031,0.415,0.941,0.499\n5860,0.0391,0.301,0.258\n4265,0.722,0.699,0.627\n2562,0.335,0.879,0.785\n7519,0.535,0.607,0.386\n8641,0.279,0.927,0.433\n5608,0.545,0.781,0.458\n2589,0.237,0.386,0.816\n5456,0.424,0.513,0.513\n2014,0.632,0.837,0.826\n1827,0.178,0.0404,0.569\n5716,0.418,0.923,0.561\n8517,0.397,0.788,0.381\n1569,0.531,0.141,0.489\n2297,0.711,0.856,0.596\n6824,0.43,0.77,0.563\n6607,0.757,0.79,0.542\n3305,0.299,0.724,0.702\n5991,0.977,0.783,0.615\n1016,0.352,0.106,0.502\n8981,0.196,0.97,0.0918\n1204,0.524,0.134,0.471\n7988,0.818,0.442,0.665\n1475,0.496,0.263,0.553\n6982,0.718,0.717,0.472\n9331,0.12,0.991,0.389\n9361,0.342,0.909,0.423\n1207,0.946,0.771,0.506\n5625,0.757,0.695,0.691\n4271,0.435,0.524,0.605\n4573,0.712,0.603,0.449\n6648,0.689,0.649,0.601\n4998,0.915,0.317,0.38\n1627,0.844,0.626,0.506\n7301,0.144,0.34,0.412\n6309,0.588,0.592,0.556\n4233,0.713,0.632,0.763\n6897,0.272,0.322,0.283\n6096,0.896,0.773,0.799\n3344,0.333,0.97,0.711\n2123,0.707,0.855,0.923\n4389,0.458,0.225,0.334\n9189,0.152,0.988,0.161\n7861,0.41,0.435,0.688\n1816,0.347,0.2,0.475\n8229,0.921,0.734,0.788\n3574,0.756,0.944,0.776\n8746,0.0838,0.913,0.144\n7324,0.131,0.15,0.295\n9859,0.679,0.703,0.597\n1285,0.442,0.581,0.275\n8283,0.311,0.826,0.701\n4839,0.0615,0.0704,0.166\n6710,0.75,0.601,0.561\n9706,0.725,0.906,0.516\n2887,0.169,0.392,0.633\n2663,0.0748,0.662,0.656\n6463,0.811,0.947,0.562\n2254,0.498,0.949,0.507\n2957,0.629,0.853,0.605\n3741,0.51,0.95,0.7\n2948,0.792,0.374,0.385\n8271,0.188,0.792,0.342\n4147,0.858,0.51,0.768\n2606,0.377,0.543,0.752\n6356,0.714,0.713,0.608\n8275,0.462,0.717,0.62\n7812,0.677,0.624,0.577\n7012,0.558,0.957,0.79\n4083,0.375,0.788,0.829\n6822,0.682,0.674,0.715\n6076,0.621,0.526,0.787\n2902,0.772,0.808,0.774\n3258,0.162,0.945,0.71\n5544,0.113,0.244,0.204\n1336,0.763,0.164,0.828\n2500,0.724,0.732,0.813\n6337,0.968,0.796,0.563\n6697,0.321,0.245,0.422\n2776,0.347,0.738,0.613\n7527,0.968,0.821,0.581\n2556,0.59,0.853,0.616\n8970,0.0399,0.991,0.161\n6312,0.759,0.626,0.431\n1477,0.594,0.43,0.437\n9627,0.757,0.667,0.744\n7754,0.311,0.247,0.29\n7205,0.327,0.327,0.298\n6410,0.436,0.249,0.496\n3259,0.174,0.828,0.614\n7756,0.693,0.678,0.329\n1304,0.937,0.767,0.281\n2121,0.437,0.758,0.539\n7700,0.455,0.488,0.651\n8556,0.529,0.412,0.502\n8244,0.718,0.944,0.625\n5798,0.902,0.872,0.842\n9398,0.22,0.974,0.249\n5192,0.579,0.658,0.387\n8730,0.64,0.824,0.579\n9220,0.494,0.948,0.492\n3439,0.377,0.812,0.602\n1895,0.823,0.352,0.482\n2674,0.35,0.729,0.364\n5976,0.739,0.594,0.843\n6065,0.403,0.647,0.649\n1335,0.566,0.425,0.575\n9504,0.944,0.913,0.751\n1105,0.682,0.919,0.677\n8652,0.0393,0.464,0.124\n5091,0.365,0.18,0.342\n7933,0.594,0.459,0.532\n2862,0.674,0.856,0.516\n6548,0.696,0.555,0.617\n6530,0.696,0.969,0.552\n7428,0.533,0.625,0.39\n7197,0.136,0.456,0.429\n2028,0.751,0.854,0.854\n2567,0.093,0.871,0.58\n2185,0.87,0.7,0.725\n3105,0.909,0.915,0.702\n1944,0.639,0.605,0.621\n7065,0.487,0.807,0.46\n8963,0.101,0.911,0.1\n7013,0.212,0.905,0.64\n8406,0.565,0.785,0.62\n4471,0.541,0.698,0.688\n2623,0.578,0.934,0.886\n6354,0.846,0.665,0.706\n4472,0.647,0.822,0.713\n2498,0.584,0.873,0.662\n9800,0.772,0.817,0.581\n1474,0.927,0.383,0.586\n5412,0.454,0.56,0.483\n7062,0.647,0.498,0.43\n3537,0.262,0.963,0.612\n9255,0.248,0.97,0.3\n1950,0.963,0.564,0.723\n9396,0.328,0.995,0.413\n9355,0.733,0.884,0.545\n8443,0.4,0.384,0.349\n3692,0.822,0.968,0.857\n1498,0.915,0.851,0.625\n6578,0.824,0.717,0.607\n2796,0.616,0.441,0.667\n8912,0.506,0.958,0.248\n5107,0.193,0.211,0.176\n1452,0.728,0.371,0.59\n4991,0.169,0.144,0.162\n8868,0.486,0.871,0.262\n2511,0.543,0.73,0.596\n6406,0.805,0.394,0.576\n8644,0.597,0.617,0.761\n4150,0.531,0.737,0.875\n7761,0.434,0.525,0.493\n2497,0.189,0.781,0.517\n5180,0.811,0.585,0.687\n1283,0.716,0.773,0.612\n9529,0.678,0.935,0.218\n3247,0.424,0.959,0.471\n9703,0.541,0.921,0.394\n8883,0.557,0.969,0.24\n3115,0.212,0.771,0.561\n2281,0.406,0.684,0.59\n9321,0.901,0.73,0.653\n9167,0.197,0.963,0.327\n5844,0.902,0.872,0.842\n2977,0.965,0.938,0.765\n9807,0.964,0.807,0.534\n7762,0.687,0.524,0.521\n8362,0.807,0.998,0.653\n3887,0.617,0.734,0.704\n2398,0.827,0.391,0.914\n8969,0.0245,0.995,0.0824\n2673,0.151,0.376,0.483\n1830,0.453,0.507,0.387\n9605,0.618,0.686,0.348\n8564,0.395,0.676,0.492\n1792,0.453,0.159,0.66\n5518,0.802,0.838,0.796\n7493,0.413,0.252,0.522\n1663,0.772,0.359,0.517\n8994,0.367,0.982,0.29\n5019,0.389,0.261,0.52\n1424,0.584,0.445,0.518\n1745,0.648,0.676,0.522\n4331,0.848,0.822,0.793\n6094,0.236,0.535,0.64\n2158,0.592,0.522,0.562\n4162,0.0361,0.112,0.286\n7473,0.417,0.327,0.268\n2883,0.898,0.951,0.837\n1149,0.609,0.168,0.697\n6564,0.845,0.754,0.363\n6659,0.222,0.248,0.343\n9029,0.83,0.71,0.854\n5595,0.891,0.888,0.555\n7116,0.276,0.452,0.257\n1052,0.304,0.231,0.436\n4203,0.771,0.683,0.686\n1987,0.44,0.877,0.705\n5903,0.706,0.467,0.702\n1114,0.952,0.44,0.724\n9497,0.624,0.96,0.412\n8785,0.162,0.95,0.431\n7603,0.499,0.939,0.474\n3298,0.139,0.985,0.745\n1327,0.577,0.561,0.69\n4123,0.784,0.611,0.8\n9085,0.162,0.994,0.507\n4939,0.709,0.52,0.583\n3509,0.661,0.906,0.703\n1098,0.975,0.816,0.604\n6872,0.208,0.39,0.38\n6651,0.393,0.507,0.631\n1825,0.335,0.305,0.432\n2184,0.556,0.938,0.324\n8964,0.251,0.712,0.157\n8053,0.85,0.941,0.408\n3988,0.965,0.718,0.764\n5429,0.742,0.679,0.848\n1754,0.574,0.246,0.625\n1815,0.845,0.475,0.476\n1390,0.861,0.631,0.581\n6746,0.306,0.279,0.373\n5392,0.89,0.803,0.71\n4610,0.582,0.675,0.542\n2898,0.671,0.95,0.851\n9502,0.664,0.967,0.537\n1577,0.334,0.163,0.425\n5244,0.419,0.884,0.678\n4276,0.955,0.724,0.742\n9047,0.332,0.952,0.436\n6950,0.367,0.998,0.482\n1894,0.558,0.171,0.727\n6817,0.745,0.841,0.515\n2848,0.522,0.977,0.682\n8954,0.0967,0.917,0.22\n5256,0.822,0.82,0.599\n1389,0.872,0.578,0.724\n1377,0.731,0.341,0.428\n3839,0.806,0.737,0.494\n3311,0.132,0.794,0.685\n6948,0.382,0.925,0.468\n4551,0.838,0.423,0.798\n7360,0.196,0.61,0.538\n1143,0.409,0.118,0.793\n3150,0.548,0.654,0.628\n8767,0.122,0.991,0.143\n3280,0.702,0.917,0.636\n9642,0.808,0.969,0.712\n2320,0.456,0.847,0.886\n1054,0.229,0.0408,0.199\n7507,0.75,0.85,0.519\n5502,0.323,0.585,0.578\n8028,0.688,0.628,0.696\n1824,0.699,0.42,0.571\n3380,0.217,0.689,0.674\n5306,0.248,0.784,0.831\n7486,0.254,0.226,0.255\n3250,0.224,0.659,0.791\n1941,0.669,0.35,0.685\n6301,0.332,0.368,0.589\n5362,0.492,0.833,0.697\n5853,0.762,0.775,0.825\n3390,0.478,0.923,0.519\n3738,0.75,0.876,0.809\n2842,0.688,0.829,0.653\n8721,0.0874,0.405,0.294\n1407,0.651,0.0655,0.655\n3592,0.564,0.869,0.639\n9068,0.349,0.947,0.564\n4584,0.298,0.204,0.362\n1027,0.0899,0.408,0.23\n7814,0.371,0.329,0.299\n9193,0.421,0.976,0.512\n7131,0.101,0.337,0.309\n6528,0.501,0.367,0.571\n6412,0.699,0.388,0.566\n8054,0.878,0.769,0.523\n2395,0.208,0.154,0.545\n9523,0.553,0.944,0.324\n1643,0.601,0.319,0.639\n1503,0.514,0.224,0.397\n7106,0.44,0.95,0.384\n4081,0.733,0.867,0.865\n7801,0.363,0.127,0.686\n5682,0.819,0.848,0.484\n8649,0.438,0.885,0.363\n7550,0.684,0.549,0.604\n1655,0.37,0.528,0.76\n1463,0.959,0.817,0.487\n9127,0.637,0.972,0.458\n1437,0.908,0.503,0.56\n6989,0.226,0.562,0.389\n9569,0.489,0.969,0.771\n9618,0.513,0.7,0.581\n2122,0.696,0.762,0.818\n2664,0.552,0.528,0.755\n7216,0.181,0.341,0.38\n2503,0.377,0.704,0.741\n5699,0.81,0.68,0.719\n9306,0.312,0.989,0.388\n8842,0.354,0.953,0.477\n8635,0.91,0.869,0.539\n2767,0.372,0.416,0.847\n5154,0.41,0.401,0.352\n4809,0.57,0.386,0.6\n2737,0.494,0.316,0.726\n5526,0.0591,0.18,0.104\n5688,0.413,0.493,0.406\n2205,0.454,0.864,0.734\n8552,0.557,0.835,0.315\n4928,0.13,0.0799,0.302\n1029,0.0387,0.0304,0.17\n7140,0.225,0.688,0.415\n4964,0.291,0.217,0.25\n3764,0.923,0.69,0.692\n3462,0.52,0.84,0.751\n6091,0.963,0.908,0.796\n6352,0.564,0.257,0.681\n1694,0.813,0.261,0.55\n2918,0.375,0.113,0.67\n4853,0.129,0.0776,0.283\n4235,0.386,0.906,0.805\n3435,0.534,0.799,0.617\n2886,0.304,0.554,0.617\n6895,0.695,0.908,0.563\n2901,0.675,0.9,0.662\n1214,0.873,0.67,0.416\n5944,0.241,0.617,0.612\n2025,0.726,0.896,0.889\n7464,0.752,0.81,0.438\n3799,0.762,0.832,0.729\n3359,0.245,0.93,0.648\n6859,0.367,0.227,0.551\n4097,0.88,0.797,0.83\n7080,0.46,0.884,0.352\n9823,0.962,0.612,0.567\n4118,0.6,0.784,0.756\n9173,0.272,0.677,0.494\n8626,0.538,0.861,0.538\n8321,0.203,0.724,0.481\n9560,0.814,0.576,0.744\n1410,0.75,0.257,0.668\n4726,0.587,0.367,0.405\n5507,0.335,0.707,0.895\n5486,0.957,0.86,0.692\n7315,0.361,0.48,0.358\n9674,0.88,0.984,0.671\n8481,0.158,0.487,0.441\n3539,0.0702,0.455,0.44\n8392,0.219,0.163,0.48\n6586,0.772,0.523,0.516\n1888,0.416,0.166,0.609\n7130,0.434,0.786,0.432\n2170,0.802,0.839,0.72\n5546,0.148,0.0988,0.186\n2834,0.155,0.544,0.537\n5497,0.678,0.0715,0.619\n9860,0.557,0.818,0.501\n1848,0.657,0.172,0.665\n9708,0.258,0.893,0.358\n4965,0.113,0.217,0.156\n3944,0.729,0.707,0.61\n1419,0.702,0.488,0.271\n1278,0.862,0.732,0.551\n2366,0.399,0.475,0.875\n9419,0.732,0.952,0.563\n4650,0.57,0.13,0.624\n5040,0.242,0.139,0.233\n7619,0.672,0.49,0.74\n6251,0.363,0.741,0.778\n6261,0.235,0.722,0.426\n7856,0.81,0.641,0.59\n5930,0.45,0.604,0.659\n1237,0.945,0.389,0.539\n1266,0.477,0.365,0.499\n8318,0.423,0.889,0.421\n4688,0.553,0.445,0.417\n6440,0.85,0.535,0.637\n2417,0.399,0.475,0.875\n4405,0.168,0.0591,0.302\n6899,0.541,0.917,0.623\n8820,0.0393,0.993,0.504\n5434,0.588,0.572,0.476\n1004,0.224,0.0958,0.429\n3188,0.0316,0.292,0.296\n3508,0.73,0.935,0.635\n9797,0.815,0.732,0.381\n3340,0.562,0.988,0.759\n8176,0.56,0.934,0.491\n4594,0.639,0.57,0.595\n5498,0.932,0.319,0.62\n6331,0.433,0.234,0.514\n6626,0.644,0.207,0.571\n3123,0.41,0.524,0.757\n5289,0.846,0.812,0.687\n2286,0.221,0.494,0.483\n8957,0.131,0.965,0.221\n3293,0.0704,0.959,0.531\n3724,0.674,0.857,0.737\n1542,0.364,0.0542,0.606\n2109,0.628,0.862,0.735\n7311,0.544,0.231,0.741\n3814,0.783,0.692,0.676\n8124,0.587,0.67,0.54\n7753,0.703,0.593,0.391\n7396,0.458,0.338,0.272\n8309,0.511,0.939,0.422\n2632,0.0732,0.85,0.47\n9276,0.0822,0.989,0.511\n8166,0.268,0.534,0.412\n1218,0.917,0.652,0.581\n7902,0.679,0.914,0.553\n7096,0.727,0.864,0.437\n3616,0.305,0.552,0.689\n7333,0.269,0.825,0.284\n9364,0.594,0.88,0.553\n2369,0.805,0.725,0.608\n3629,0.824,0.761,0.856\n8680,0.198,0.444,0.518\n3016,0.523,0.761,0.55\n2626,0.644,0.733,0.805\n8396,0.518,0.644,0.581\n7239,0.136,0.579,0.359\n2794,0.222,0.651,0.533\n4041,0.748,0.74,0.953\n2305,0.262,0.938,0.662\n3904,0.681,0.59,0.927\n1771,0.596,0.437,0.533\n5972,0.606,0.821,0.647\n5792,0.919,0.595,0.827\n1083,0.734,0.375,0.807\n2303,0.546,0.997,0.643\n4082,0.657,0.847,0.57\n9130,0.478,0.866,0.387\n3613,0.285,0.994,0.59\n1835,0.496,0.132,0.732\n6763,0.489,0.58,0.522\n6088,0.325,0.88,0.737\n2970,0.58,0.723,0.82\n7805,0.951,0.522,0.589\n7703,0.765,0.829,0.52\n8742,0.164,0.822,0.315\n6665,0.225,0.256,0.377\n5700,0.538,0.854,0.758\n6616,0.614,0.218,0.658\n4054,0.267,0.618,0.744\n7144,0.868,0.887,0.317\n8613,0.13,0.52,0.612\n2359,0.106,0.978,0.566\n6686,0.577,0.755,0.275\n5119,0.842,0.427,0.443\n7640,0.931,0.813,0.439\n4067,0.82,0.761,0.774\n1802,0.751,0.0884,0.66\n6194,0.761,0.818,0.667\n7912,0.338,0.366,0.435\n3220,0.174,0.761,0.602\n7389,0.872,0.796,0.678\n8628,0.591,0.727,0.613\n3541,0.279,0.547,0.772\n7948,0.535,0.58,0.354\n8238,0.453,0.831,0.313\n8060,0.267,0.498,0.272\n4846,0.802,0.329,0.631\n7932,0.407,0.315,0.561\n4567,0.548,0.511,0.386\n3810,0.662,0.448,0.734\n7366,0.0468,0.384,0.581\n1179,0.657,0.147,0.589\n5005,0.498,0.484,0.271\n5436,0.332,0.501,0.731\n1602,0.805,0.426,0.647\n3261,0.682,0.951,0.735\n2827,0.493,0.829,0.704\n8749,0.441,0.963,0.439\n7611,0.862,0.596,0.374\n7915,0.341,0.42,0.313\n9213,0.515,0.935,0.407\n3069,0.719,0.844,0.427\n4277,0.794,0.889,0.771\n2610,0.826,0.515,0.803\n9280,0.167,0.861,0.206\n2024,0.62,0.762,0.895\n2582,0.462,0.635,0.679\n1869,0.569,0.232,0.51\n3936,0.15,0.818,0.423\n3404,0.69,0.681,0.71\n5957,0.711,0.909,0.561\n8572,0.247,0.0799,0.456\n2627,0.918,0.614,0.871\n6873,0.554,0.849,0.6\n3886,0.789,0.739,0.631\n6066,0.962,0.627,0.793\n9404,0.734,0.947,0.397\n9525,0.196,0.913,0.291\n1166,0.865,0.701,0.562\n7397,0.937,0.677,0.672\n1366,0.687,0.367,0.615\n7870,0.694,0.654,0.453\n4208,0.187,0.528,0.634\n8004,0.48,0.112,0.501\n2832,0.524,0.893,0.495\n8181,0.75,0.841,0.542\n3513,0.165,0.739,0.647\n7393,0.82,0.702,0.493\n7252,0.721,0.394,0.694\n6782,0.0378,0.328,0.0916\n9625,0.286,0.111,0.609\n8012,0.754,0.663,0.614\n6806,0.961,0.889,0.315\n3889,0.899,0.808,0.678\n7979,0.308,0.331,0.576\n6687,0.568,0.264,0.466\n8418,0.261,0.38,0.468\n7336,0.642,0.872,0.306\n5266,0.482,0.822,0.636\n1789,0.76,0.332,0.616\n8068,0.7,0.975,0.313\n5389,0.537,0.756,0.67\n6963,0.451,0.742,0.307\n3374,0.374,0.853,0.553\n5382,0.291,0.296,0.872\n6262,0.718,0.956,0.623\n5530,0.0862,0.264,0.249\n1563,0.535,0.177,0.5\n2687,0.0467,0.72,0.935\n2617,0.373,0.893,0.798\n3888,0.791,0.656,0.546\n2538,0.131,0.868,0.55\n3417,0.0945,0.863,0.607\n7036,0.484,0.609,0.539\n9464,0.748,0.967,0.281\n9842,0.837,0.678,0.595\n7571,0.426,0.786,0.526\n1718,0.498,0.133,0.501\n3357,0.331,0.935,0.647\n6273,0.5,0.731,0.484\n5035,0.421,0.3,0.197\n3651,0.599,0.62,0.643\n5523,0.0486,0.388,0.693\n2646,0.438,0.536,0.832\n1654,0.882,0.562,0.545\n4894,0.513,0.469,0.497\n9349,0.464,0.957,0.192\n1422,0.588,0.394,0.492\n5945,0.0879,0.449,0.493\n8724,0.487,0.784,0.679\n3983,0.881,0.306,0.875\n8250,0.543,0.673,0.364\n3533,0.258,0.6,0.79\n6894,0.599,0.912,0.694\n7064,0.316,0.753,0.298\n2148,0.805,0.474,0.675\n6939,0.612,0.979,0.604\n1433,0.91,0.793,0.507\n1698,0.305,0.177,0.441\n8442,0.318,0.526,0.549\n5551,0.0393,0.17,0.186\n3104,0.158,0.222,0.417\n3965,0.706,0.638,0.737\n6504,0.103,0.129,0.573\n7338,0.337,0.592,0.316\n6704,0.536,0.404,0.366\n8247,0.477,0.949,0.431\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b08ad528e19bac907d41de885e030cd729f0d329"
      },
      "cell_type": "code",
      "source": "path = \"../input/data/data/multitask_dataset/train\"\nprint('Files in multitask_dataset/train folder')\n#print(os.listdir(path))",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Files in multitask_dataset/train folder\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb931f8d029b69a4e502f62e122db6280b15e7cd"
      },
      "cell_type": "code",
      "source": "import copy\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import SubsetRandomSampler, DataLoader",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3eb50b09f61ce5aac2d1851bee3d0a440f571722"
      },
      "cell_type": "code",
      "source": "def torch_train_val_split(dataset, batch_train, batch_eval,val_size=.2, shuffle=True, seed=42):\n    # Creating data indices for training and validation splits:\n    dataset_size = len(dataset)\n    indices = list(range(dataset_size))\n    val_split = int(np.floor(val_size * dataset_size))\n    if shuffle:\n        np.random.seed(seed)\n        np.random.shuffle(indices)\n    train_indices = indices[val_split:]\n    val_indices = indices[:val_split]\n\n    # Creating PT data samplers and loaders:\n    train_sampler = SubsetRandomSampler(train_indices)\n    val_sampler = SubsetRandomSampler(val_indices)\n\n    train_loader = DataLoader(dataset,\n                              batch_size=batch_train,\n                              sampler=train_sampler)\n    val_loader = DataLoader(dataset,\n                            batch_size=batch_eval,\n                            sampler=val_sampler)\n    return train_loader, val_loader",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "81495ac8f36cdf724d6facfba19ad00bd7ad44a5"
      },
      "cell_type": "code",
      "source": "def read_spectrogram(spectrogram_file, chroma=True):\n    with gzip.GzipFile(spectrogram_file, 'r') as f:\n        spectrograms = np.load(f)\n    # spectrograms contains a fused mel spectrogram and chromagram\n    # Decompose as follows\n    return spectrograms.T",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b3d7776b13e6d8899cc5db84b1123aeca07efaca"
      },
      "cell_type": "code",
      "source": "class LabelTransformer(LabelEncoder):\n    def inverse(self, y):\n        try:\n            return super(LabelTransformer, self).inverse_transform(y)\n        except:\n            return super(LabelTransformer, self).inverse_transform([y])\n\n    def transform(self, y):\n        try:\n            return super(LabelTransformer, self).transform(y)\n        except:\n            return super(LabelTransformer, self).transform([y])",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73a6bc5d0d810676197206672c2951ed0cad65f4"
      },
      "cell_type": "code",
      "source": "class PaddingTransform(object):\n    def __init__(self, max_length, padding_value=0):\n        self.max_length = max_length\n        self.padding_value = padding_value\n\n    def __call__(self, s):\n        if len(s) == self.max_length:\n            return s\n\n        if len(s) > self.max_length:\n            return s[:self.max_length]\n\n        if len(s) < self.max_length:\n            s1 = copy.deepcopy(s)\n            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n            s1 = np.vstack((s1, pad))\n            return s1",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c55a132d49bc6ef39829b96244c8959094da00c9"
      },
      "cell_type": "code",
      "source": "class MultitaskDataset(Dataset):\n    def __init__(self, path, class_mapping=None, train=True, max_length=-1):\n        t = 'train' if train else 'test'\n        p = os.path.join(path, t)\n        self.train = False\n        if train:\n            self.train = True\n            self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n            self.files, labels1, labels2, labels3 = self.get_files_labels(self.index, class_mapping)\n        else:\n            self.files = os.listdir(p)\n\n        self.feats = [read_spectrogram(os.path.join(p, f)) for f in self.files]\n        self.feat_dim = self.feats[0].shape[1]\n        self.lengths = [len(i) for i in self.feats]\n        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n        if self.train:\n            self.label_transformer = LabelTransformer()\n        \n            if isinstance(labels1, (list, tuple)):\n                self.labels1 = labels1\n            if isinstance(labels2, (list, tuple)):\n                self.labels2 = labels2\n            if isinstance(labels3, (list, tuple)):\n                self.labels3 = labels3\n\n    def get_files_labels(self, txt, class_mapping):\n        with open(txt, 'r') as fd:\n            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n            #print(lines)\n        files, labels1, labels2, labels3 = [], [], [], []\n        for l in lines:\n            chars = l[0].split(\",\")\n            #print(chars[1])\n            #print(chars[0]+'.fused.full.npy.gz')\n            files.append(chars[0]+'.fused.full.npy.gz')\n            labels1.append(float(chars[1]))\n            labels2.append(float(chars[2]))\n            labels3.append(float(chars[3]))\n        return files, labels1, labels2, labels3\n\n    def __getitem__(self, item):\n        l = min(self.lengths[item], self.max_length)\n        if self.train:\n            return self.zero_pad_and_stack(self.feats[item]), self.labels1[item], self.labels2[item], self.labels3[item], l\n        else:\n            return self.zero_pad_and_stack(self.feats[item]), l\n    def __len__(self):\n        return len(self.files)        ",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2fafc6ee7e01e7c586af4bfd84bf555456fcbbed"
      },
      "cell_type": "code",
      "source": "specs = MultitaskDataset('../input/data/data/multitask_dataset/', train=True, class_mapping=None, max_length=-1)\ntrain_loader, val_loader = torch_train_val_split(specs, 45, 45, val_size=.33)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "131699008905bc970e1c4c0cb886ea6e9322ae38"
      },
      "cell_type": "code",
      "source": "import torch\nfrom torch import nn\nfrom torch.autograd import Variable\nimport math \n\nclass CNN_d2(nn.Module):\n    def __init__(self, num_classes,timesteps,num_features):\n        super(CNN_d2, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 4, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(4),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(4, 10, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(10),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(10, 15, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(15),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(15, 20, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(20),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.dropout = nn.Dropout(0.01)\n        cnn_out_dim = int(math.floor(timesteps/16)*math.floor(num_features/16))*20\n        self.fc1 = nn.Linear(cnn_out_dim, math.floor(cnn_out_dim/10))\n        self.fc2 = nn.Linear(math.floor(cnn_out_dim/10), math.floor(cnn_out_dim/100))\n        self.fc3 = nn.Linear(math.floor(cnn_out_dim/100), 1)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.dropout(out)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        out = self.fc3(out)\n        return out",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ca7c548a329d375e465db8f6c785d304a63e11c"
      },
      "cell_type": "code",
      "source": "def eval_pred(features, model):\n    output_tensor = model(features.unsqueeze_(1))\n    batch_pred = output_tensor.view(1,-1)[0].detach()\n    return batch_pred, output_tensor",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56d94bdcd6f9d0cc9c8dc22c8755ae4b8e6d051f"
      },
      "cell_type": "code",
      "source": "from scipy.stats import spearmanr\n\ndef train_val_loop(epochs,model,criterion,optimizer,task):\n    \n    for epoch in range(epochs):\n        #train loop\n        train_loss = 0.0\n\n        for i, data in enumerate(train_loader):\n            features = torch.tensor(data[0]).float().cuda()\n            labels = torch.tensor(data[task]).float().cuda()\n            \n            optimizer.zero_grad()           \n            output = model(features.unsqueeze_(1))\n            \n            #print(\"OUT \\n\",output.permute(1,0))\n            #print(\"Lab \\n\",labels)\n            \n            loss = criterion(output.permute(1,0),labels)\n            loss.backward()\n            optimizer.step()\n            train_loss = train_loss + loss\n\n        num_batch_train = i+1\n\n        val_loss = 0.0\n        f1_val = 0.0\n        \n        #validation loop\n        for j, data_val in enumerate(val_loader):\n            features_val = torch.tensor(data_val[0]).float().cuda()\n            labels_val = torch.tensor(data_val[task]).float().cuda()\n\n            batch_pred, output_tensor = eval_pred(features_val, model)\n            \n            loss_val = criterion(output_tensor.permute(1,0),labels_val)\n            val_loss = val_loss + loss_val\n            #print(\"Batch Pred:\", batch_pred)\n            #print(\"Labels Val:\", labels_val)\n            #f1_val = f1_val + accuracy_score(labels_val.cpu(), batch_pred.cpu())\n            #corr, _ = spearmanr(labels_val.cpu().squeeze().detach().numpy(), output_tensor.cpu().permute(1,0).squeeze().detach().numpy())\n            #print(corr)\n        num_batch_val = j+1    \n        #f1_val = f1_val/num_batch_val\n        \n        print ('Epoch %d from %d, Train loss: %.4f' %(epoch + 1, epochs, train_loss/num_batch_train))\n        print ('Epoch %d from %d, Validation loss: %.4f' %(epoch + 1, epochs, val_loss/num_batch_val))\n        #print('Score in validation set is: %d %%' % (100 * f1_val))\n        print('--------------------------------')\n    return",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6db0ae4a2cb7a5d1a5426a21a4232a50b8868c31"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnum_classes = 2\ntimesteps = 1293\nnum_features = 140\n\nmodel1 = CNN_d2(num_classes,timesteps,num_features)\nmodel1.cuda()\n\nprint('Training Loop for 2D CNN - Predictions for Valence')\n\nepochs = 100\nLR = 0.0008\nweight_decay=0.0000005\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model1.parameters(), weight_decay=weight_decay, lr=LR)\ntrain_val_loop(epochs,model1,criterion,optimizer,1)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Training Loop for 2D CNN - Predictions for Valence\nEpoch 1 from 10, Train loss: 0.0853\nEpoch 1 from 10, Validation loss: 0.0664\n--------------------------------\nEpoch 2 from 10, Train loss: 0.0633\nEpoch 2 from 10, Validation loss: 0.0678\n--------------------------------\nEpoch 3 from 10, Train loss: 0.0621\nEpoch 3 from 10, Validation loss: 0.0653\n--------------------------------\nEpoch 4 from 10, Train loss: 0.0602\nEpoch 4 from 10, Validation loss: 0.0678\n--------------------------------\nEpoch 5 from 10, Train loss: 0.0587\nEpoch 5 from 10, Validation loss: 0.0641\n--------------------------------\nEpoch 6 from 10, Train loss: 0.0574\nEpoch 6 from 10, Validation loss: 0.0682\n--------------------------------\nEpoch 7 from 10, Train loss: 0.0562\nEpoch 7 from 10, Validation loss: 0.0701\n--------------------------------\nEpoch 8 from 10, Train loss: 0.0566\nEpoch 8 from 10, Validation loss: 0.0666\n--------------------------------\nEpoch 9 from 10, Train loss: 0.0554\nEpoch 9 from 10, Validation loss: 0.0612\n--------------------------------\nEpoch 10 from 10, Train loss: 0.0542\nEpoch 10 from 10, Validation loss: 0.0625\n--------------------------------\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f02432cd8a8de943a592d22db10f550482489e2"
      },
      "cell_type": "code",
      "source": "\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnum_classes = 2\ntimesteps = 1293\nnum_features = 140\n\nmodel2 = CNN_d2(num_classes,timesteps,num_features)\nmodel2.cuda()\n\nprint('Training Loop for 2D CNN - Predictions for Energy')\n\nepochs = 100\nLR = 0.0008\nweight_decay=0.0000005\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model2.parameters(), weight_decay=0, lr=LR)\ntrain_val_loop(epochs,model2,criterion,optimizer,2)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Training Loop for 2D CNN - Predictions for Energy\nEpoch 1 from 10, Train loss: 0.0834\nEpoch 1 from 10, Validation loss: 0.0483\n--------------------------------\nEpoch 2 from 10, Train loss: 0.0445\nEpoch 2 from 10, Validation loss: 0.0399\n--------------------------------\nEpoch 3 from 10, Train loss: 0.0369\nEpoch 3 from 10, Validation loss: 0.0333\n--------------------------------\nEpoch 4 from 10, Train loss: 0.0329\nEpoch 4 from 10, Validation loss: 0.0366\n--------------------------------\nEpoch 5 from 10, Train loss: 0.0321\nEpoch 5 from 10, Validation loss: 0.0334\n--------------------------------\nEpoch 6 from 10, Train loss: 0.0310\nEpoch 6 from 10, Validation loss: 0.0355\n--------------------------------\nEpoch 7 from 10, Train loss: 0.0322\nEpoch 7 from 10, Validation loss: 0.0332\n--------------------------------\nEpoch 8 from 10, Train loss: 0.0323\nEpoch 8 from 10, Validation loss: 0.0320\n--------------------------------\nEpoch 9 from 10, Train loss: 0.0299\nEpoch 9 from 10, Validation loss: 0.0323\n--------------------------------\nEpoch 10 from 10, Train loss: 0.0301\nEpoch 10 from 10, Validation loss: 0.0315\n--------------------------------\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd5b574fa73d8736852ae029f289806ffa56be91"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnum_classes = 2\ntimesteps = 1293\nnum_features = 140\n\nmodel3 = CNN_d2(num_classes,timesteps,num_features)\nmodel3.cuda()\n\nprint('Training Loop for 2D CNN - Predictions for Danceability')\n\nepochs = 100\nLR = 0.0008\nweight_decay=0.0000005\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model3.parameters(), weight_decay=weight_decay, lr=LR)\ntrain_val_loop(epochs,model3,criterion,optimizer,3)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Training Loop for 2D CNN - Predictions for Danceability\nEpoch 1 from 10, Train loss: 0.0387\nEpoch 1 from 10, Validation loss: 0.0279\n--------------------------------\nEpoch 2 from 10, Train loss: 0.0249\nEpoch 2 from 10, Validation loss: 0.0283\n--------------------------------\nEpoch 3 from 10, Train loss: 0.0242\nEpoch 3 from 10, Validation loss: 0.0266\n--------------------------------\nEpoch 4 from 10, Train loss: 0.0230\nEpoch 4 from 10, Validation loss: 0.0282\n--------------------------------\nEpoch 5 from 10, Train loss: 0.0232\nEpoch 5 from 10, Validation loss: 0.0264\n--------------------------------\nEpoch 6 from 10, Train loss: 0.0213\nEpoch 6 from 10, Validation loss: 0.0253\n--------------------------------\nEpoch 7 from 10, Train loss: 0.0217\nEpoch 7 from 10, Validation loss: 0.0256\n--------------------------------\nEpoch 8 from 10, Train loss: 0.0207\nEpoch 8 from 10, Validation loss: 0.0239\n--------------------------------\nEpoch 9 from 10, Train loss: 0.0201\nEpoch 9 from 10, Validation loss: 0.0229\n--------------------------------\nEpoch 10 from 10, Train loss: 0.0198\nEpoch 10 from 10, Validation loss: 0.0244\n--------------------------------\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f7feff795accd6a804b07e769bc2989ee600a67"
      },
      "cell_type": "code",
      "source": "test_loader = DataLoader(MultitaskDataset('../input/data/data/multitask_dataset/', train=False, class_mapping=None, max_length=-1), batch_size=45)",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "fa5518a6e6cc4ae168d7e96a55a24cffd375276b"
      },
      "cell_type": "code",
      "source": "f = open('../results.txt', 'w')\nf.write('Id.fused.full.npy.gz,valence,energy,danceability\\n')\nfor j, data_test in enumerate(test_loader):\n    #print(j)\n    features = torch.tensor(data_test[0]).float().cuda()\n    #labels_val = torch.tensor(data_test[task]).float().cuda()\n    #print(data_test.shape[0])\n    batch_pred1, _ = eval_pred(features, model1)\n    features = torch.tensor(data_test[0]).float().cuda()\n    batch_pred2, _ = eval_pred(features, model2)\n    features = torch.tensor(data_test[0]).float().cuda()\n    batch_pred3, _ = eval_pred(features, model3)\n    for i in range(len(features)):\n        #print(i)\n        file = os.listdir('../input/data/data/multitask_dataset/test')[45*j+i]\n        text = file + ',' + str(batch_pred1[i].cpu().numpy()) + ',' + str(batch_pred2[i].cpu().numpy()) + ',' + str(batch_pred3[i].cpu().numpy())\n        f.write(text + '\\n')\n        #print(text)\n\n\n\n    \n",
      "execution_count": 57,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9df5b55dc839fc1ef2dc7d1e3b66feff4d53f3a7"
      },
      "cell_type": "code",
      "source": "torch.save(model1, \"../model01.pkl\")\ntorch.save(model2, \"../model02.pkl\")\ntorch.save(model3, \"../model03.pkl\")\n",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e151f9fd87c5f94e652009a03469fe6aa43e9c9"
      },
      "cell_type": "code",
      "source": "cat ../results.txt",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Id.fused.full.npy.gz,valence,energy,danceability\r\n8001.fused.full.npy.gz,0.39160743,0.44790483,0.17936091\r\n2536.fused.full.npy.gz,0.6210599,0.8457909,0.4773945\r\n8639.fused.full.npy.gz,0.5294733,0.9861921,0.3749345\r\n7551.fused.full.npy.gz,0.64374316,0.684352,0.4951082\r\n1858.fused.full.npy.gz,0.5013047,0.27624148,0.5157372\r\n8579.fused.full.npy.gz,0.43141583,0.25113422,0.41416055\r\n9289.fused.full.npy.gz,0.53995836,0.9267718,0.461675\r\n6605.fused.full.npy.gz,0.52113,0.4618075,0.49082953\r\n2540.fused.full.npy.gz,0.4850336,0.7509626,0.5601974\r\n9118.fused.full.npy.gz,0.48730603,0.72465444,0.653144\r\n4393.fused.full.npy.gz,0.56201303,0.516014,0.75489223\r\n2338.fused.full.npy.gz,0.4821874,0.5595163,0.5358801\r\n5467.fused.full.npy.gz,0.63149285,0.78666914,0.5158343\r\n9377.fused.full.npy.gz,0.5314431,0.7493486,0.56870365\r\n1870.fused.full.npy.gz,0.5044454,0.27312535,0.5133971\r\n3857.fused.full.npy.gz,0.57833016,0.8237818,0.5468643\r\n2438.fused.full.npy.gz,0.5261977,0.32667267,0.46870363\r\n5623.fused.full.npy.gz,0.5456499,0.70877665,0.54071736\r\n9110.fused.full.npy.gz,0.43113953,0.8780923,0.48394325\r\n6228.fused.full.npy.gz,0.7931427,0.3758846,0.7763283\r\n9063.fused.full.npy.gz,0.504338,0.89843714,0.41546658\r\n8898.fused.full.npy.gz,0.58666253,0.88649356,0.41929325\r\n8580.fused.full.npy.gz,0.5028384,0.84190106,0.5319495\r\n6706.fused.full.npy.gz,0.41261706,0.7263784,0.42936015\r\n3594.fused.full.npy.gz,0.4916267,0.844151,0.6858723\r\n2187.fused.full.npy.gz,0.52175134,0.73787546,0.6186491\r\n8310.fused.full.npy.gz,0.5634217,0.9174761,0.38154235\r\n7055.fused.full.npy.gz,0.3661833,0.50668466,0.5993597\r\n1890.fused.full.npy.gz,0.45806682,0.2874022,0.4040674\r\n4770.fused.full.npy.gz,0.5368233,0.619169,0.70570105\r\n3147.fused.full.npy.gz,0.46973956,0.693333,0.7069422\r\n5516.fused.full.npy.gz,0.5514819,0.69239414,0.5965897\r\n1320.fused.full.npy.gz,0.5168387,0.49790347,0.5790024\r\n2325.fused.full.npy.gz,0.61544836,0.7339097,0.7482159\r\n1881.fused.full.npy.gz,0.54312944,0.27066493,0.4987821\r\n6126.fused.full.npy.gz,0.5045761,0.7701089,0.8387587\r\n1115.fused.full.npy.gz,0.7233913,0.60505414,0.5193477\r\n8252.fused.full.npy.gz,0.57571054,0.803734,0.3834748\r\n8256.fused.full.npy.gz,0.36963233,0.58771056,0.5500849\r\n3018.fused.full.npy.gz,0.5234767,0.80252206,0.6125177\r\n2942.fused.full.npy.gz,0.5688431,0.66867054,0.7050499\r\n1860.fused.full.npy.gz,0.5015775,0.30412388,0.5290945\r\n9080.fused.full.npy.gz,0.47929153,0.97557867,0.3908699\r\n9166.fused.full.npy.gz,0.5427023,0.99149084,0.42763972\r\n1811.fused.full.npy.gz,0.5354941,0.45380783,0.70818555\r\n1445.fused.full.npy.gz,0.39755058,0.363904,0.5137877\r\n4653.fused.full.npy.gz,0.38844487,0.30656993,0.45943\r\n9829.fused.full.npy.gz,0.5747818,0.6236365,0.51754636\r\n7053.fused.full.npy.gz,0.57847977,0.8166968,0.48148823\r\n6227.fused.full.npy.gz,0.600032,0.62160355,0.56697685\r\n5060.fused.full.npy.gz,0.53104323,0.26888472,0.4788014\r\n7742.fused.full.npy.gz,0.56654346,0.8989822,0.5117536\r\n2376.fused.full.npy.gz,0.5041982,0.8670832,0.5461516\r\n2215.fused.full.npy.gz,0.45130998,0.76706165,0.6287453\r\n1196.fused.full.npy.gz,0.45342618,0.34163713,0.5084966\r\n5769.fused.full.npy.gz,0.55232596,0.5466421,0.64323133\r\n9541.fused.full.npy.gz,0.59543896,0.8578125,0.67457753\r\n2496.fused.full.npy.gz,0.67393494,0.7238174,0.53158116\r\n9119.fused.full.npy.gz,0.5653926,0.95256615,0.4363427\r\n4240.fused.full.npy.gz,0.7261462,0.7050631,0.760289\r\n8013.fused.full.npy.gz,0.58253455,0.50797415,0.54122186\r\n3148.fused.full.npy.gz,0.50337684,0.88823557,0.43016133\r\n3160.fused.full.npy.gz,0.44996044,0.29955035,0.37029895\r\n5296.fused.full.npy.gz,0.67707455,0.74505836,0.6031816\r\n7047.fused.full.npy.gz,0.55987924,0.72827405,0.60484874\r\n5896.fused.full.npy.gz,0.6155684,0.82408184,0.6121991\r\n2909.fused.full.npy.gz,0.51648235,0.7792568,0.42302072\r\n1078.fused.full.npy.gz,0.45963803,0.63744396,0.5047733\r\n2939.fused.full.npy.gz,0.579497,0.9631034,0.48006544\r\n4457.fused.full.npy.gz,0.61138237,0.593366,0.5521551\r\n2357.fused.full.npy.gz,0.50634027,0.7596277,0.6264368\r\n5816.fused.full.npy.gz,0.67684376,0.7925981,0.4822735\r\n4571.fused.full.npy.gz,0.4758347,0.5793941,0.4951056\r\n8355.fused.full.npy.gz,0.6546141,0.5128545,0.61985224\r\n4003.fused.full.npy.gz,0.82180846,0.85316724,0.75899786\r\n1704.fused.full.npy.gz,0.4813022,0.639415,0.47455463\r\n8201.fused.full.npy.gz,0.616753,0.9666573,0.52302855\r\n8863.fused.full.npy.gz,0.57245183,0.6866774,0.6254497\r\n9026.fused.full.npy.gz,0.557297,1.0578197,0.42564628\r\n5588.fused.full.npy.gz,0.5700394,0.88295156,0.4594315\r\n2880.fused.full.npy.gz,0.67551386,0.65049404,0.6876278\r\n3809.fused.full.npy.gz,0.51133585,0.43588465,0.53353816\r\n7181.fused.full.npy.gz,0.6003971,0.64038086,0.43513203\r\n9247.fused.full.npy.gz,0.6080631,1.0177917,0.4702882\r\n6624.fused.full.npy.gz,0.47650492,0.33258265,0.4602117\r\n4912.fused.full.npy.gz,0.46656337,0.48910493,0.65307766\r\n2572.fused.full.npy.gz,0.5554215,0.8497261,0.49074614\r\n5913.fused.full.npy.gz,0.60882413,0.71566,0.5965057\r\n6519.fused.full.npy.gz,0.5105475,0.47642404,0.4975333\r\n2443.fused.full.npy.gz,0.5357756,0.83246833,0.5787045\r\n2988.fused.full.npy.gz,0.7994969,0.5569638,0.64187384\r\n5577.fused.full.npy.gz,0.6960918,0.9256619,0.4612791\r\n9434.fused.full.npy.gz,0.57652026,0.943908,0.40277642\r\n2738.fused.full.npy.gz,0.6492785,0.6078217,0.56272376\r\n9274.fused.full.npy.gz,0.5825629,0.9510611,0.3970295\r\n4517.fused.full.npy.gz,0.61457694,0.45393324,0.6247235\r\n1092.fused.full.npy.gz,0.65479565,0.67501974,0.4573362\r\n6064.fused.full.npy.gz,0.4958264,0.843376,0.50142384\r\n3618.fused.full.npy.gz,0.6238005,0.4708283,0.5873411\r\n6991.fused.full.npy.gz,0.55694026,0.9221871,0.4593912\r\n8167.fused.full.npy.gz,0.52976316,0.8138037,0.45061386\r\n2414.fused.full.npy.gz,0.46165034,0.58073616,0.5291513\r\n7859.fused.full.npy.gz,0.6195867,0.7143028,0.53173864\r\n2635.fused.full.npy.gz,0.5707375,0.5734912,0.74274284\r\n4024.fused.full.npy.gz,0.46554714,0.76911813,0.6182912\r\n4510.fused.full.npy.gz,0.6465211,0.5998942,0.6831615\r\n9358.fused.full.npy.gz,0.49600014,0.8290358,0.4840176\r\n4075.fused.full.npy.gz,0.58597314,0.3919174,0.6237385\r\n2665.fused.full.npy.gz,0.42181233,0.7845211,0.8017671\r\n6846.fused.full.npy.gz,0.39016488,0.5869785,0.36753774\r\n9050.fused.full.npy.gz,0.47844025,0.9488785,0.42872956\r\n2581.fused.full.npy.gz,0.63615537,0.8645443,0.57877487\r\n9738.fused.full.npy.gz,0.5107554,0.54325163,0.59303665\r\n8397.fused.full.npy.gz,0.5454868,0.7488083,0.49361634\r\n4532.fused.full.npy.gz,0.66518736,0.7147533,0.51911825\r\n3748.fused.full.npy.gz,0.5988803,1.0302289,0.4786946\r\n8536.fused.full.npy.gz,0.5346496,0.5684651,0.5979193\r\n8640.fused.full.npy.gz,0.4931003,0.4410258,0.59219974\r\n8183.fused.full.npy.gz,0.56113935,0.7053983,0.53651726\r\n5134.fused.full.npy.gz,0.55084586,0.5517253,0.5065431\r\n4859.fused.full.npy.gz,0.492411,0.24723108,0.52825314\r\n8697.fused.full.npy.gz,0.5231205,0.92877793,0.47021934\r\n9250.fused.full.npy.gz,0.49067408,0.9095582,0.48256326\r\n7044.fused.full.npy.gz,0.58674335,0.78704405,0.54656076\r\n7450.fused.full.npy.gz,0.6375916,0.7506268,0.4869125\r\n1652.fused.full.npy.gz,0.6255703,0.9062304,0.37163898\r\n4397.fused.full.npy.gz,0.4803329,0.24783753,0.45425904\r\n4600.fused.full.npy.gz,0.32596755,0.30275023,0.33380833\r\n9312.fused.full.npy.gz,0.61059237,0.9654795,0.39490533\r\n7489.fused.full.npy.gz,0.44989067,0.6594968,0.5104277\r\n3665.fused.full.npy.gz,0.5820577,0.7130656,0.56744075\r\n1608.fused.full.npy.gz,0.7127137,0.27786833,0.5619299\r\n6796.fused.full.npy.gz,0.47749448,0.6823115,0.48327458\r\n1564.fused.full.npy.gz,0.3718437,0.4436682,0.52495176\r\n3178.fused.full.npy.gz,0.37750903,0.61283976,0.7820397\r\n2565.fused.full.npy.gz,0.50601864,0.7752403,0.66248995\r\n1039.fused.full.npy.gz,0.56378376,0.43964612,0.6417929\r\n5248.fused.full.npy.gz,0.33995736,0.2301021,0.535463\r\n3394.fused.full.npy.gz,0.6811929,0.8100006,0.62092716\r\n4291.fused.full.npy.gz,0.38234687,0.604522,0.7105384\r\n8249.fused.full.npy.gz,0.51803714,0.6205823,0.53955346\r\n1019.fused.full.npy.gz,0.45700404,0.3076691,0.38522857\r\n9745.fused.full.npy.gz,0.5999086,0.88066065,0.42351267\r\n1394.fused.full.npy.gz,0.63168764,0.9102571,0.6097865\r\n1613.fused.full.npy.gz,0.5211259,0.40981537,0.6543855\r\n6379.fused.full.npy.gz,0.5891471,0.48068738,0.59194666\r\n8232.fused.full.npy.gz,0.5589613,0.6561809,0.5470477\r\n2410.fused.full.npy.gz,0.5286919,0.7002271,0.5556458\r\n8910.fused.full.npy.gz,0.48939383,0.98326206,0.46445483\r\n5350.fused.full.npy.gz,0.58272004,0.16839126,0.42261368\r\n3499.fused.full.npy.gz,0.44484437,0.8005378,0.5062936\r\n1691.fused.full.npy.gz,0.43341032,0.28875226,0.41447347\r\n3783.fused.full.npy.gz,0.57293,0.786772,0.54480135\r\n8157.fused.full.npy.gz,0.49015298,0.769705,0.453284\r\n2682.fused.full.npy.gz,0.6010997,0.5844705,0.69869596\r\n1850.fused.full.npy.gz,0.6596782,0.53467226,0.6197237\r\n1211.fused.full.npy.gz,0.5185281,0.8632625,0.5190307\r\n9179.fused.full.npy.gz,0.5237475,0.95351446,0.48070416\r\n7469.fused.full.npy.gz,0.45504525,0.606235,0.45785052\r\n3517.fused.full.npy.gz,0.49259964,0.7856406,0.7437338\r\n5247.fused.full.npy.gz,0.5565531,0.84515095,0.6888736\r\n4855.fused.full.npy.gz,0.5038227,0.41572732,0.30433226\r\n3500.fused.full.npy.gz,0.5054549,0.7676037,0.59576046\r\n2401.fused.full.npy.gz,0.57788026,0.27290654,0.60182124\r\n5395.fused.full.npy.gz,0.6107187,0.44845498,0.6137368\r\n4767.fused.full.npy.gz,0.4359617,0.43118507,0.57079536\r\n5128.fused.full.npy.gz,0.5886775,0.797369,0.58826053\r\n5582.fused.full.npy.gz,0.6133561,0.9253337,0.46211347\r\n3505.fused.full.npy.gz,0.5658901,0.8891896,0.5836045\r\n4106.fused.full.npy.gz,0.60830843,0.7319474,0.5622168\r\n5503.fused.full.npy.gz,0.6034709,0.6796599,0.8158108\r\n5032.fused.full.npy.gz,0.46878326,0.51962095,0.41384947\r\n1344.fused.full.npy.gz,0.46579403,0.51712376,0.4862052\r\n7453.fused.full.npy.gz,0.55251944,0.54073364,0.54907763\r\n3885.fused.full.npy.gz,0.677166,0.8443038,0.51567847\r\n9035.fused.full.npy.gz,0.521623,0.93406886,0.4730723\r\n6652.fused.full.npy.gz,0.64104867,1.011395,0.47844836\r\n3606.fused.full.npy.gz,0.45152494,0.6131264,0.4876914\r\n6167.fused.full.npy.gz,0.6430992,0.84485394,0.4380175\r\n3722.fused.full.npy.gz,0.46062386,0.9348271,0.5123097\r\n2274.fused.full.npy.gz,0.55923307,0.4745463,0.5974616\r\n7383.fused.full.npy.gz,0.6266123,0.60573655,0.5085865\r\n1610.fused.full.npy.gz,0.43445483,0.2924016,0.5286422\r\n2524.fused.full.npy.gz,0.51256734,0.45081866,0.63262403\r\n3601.fused.full.npy.gz,0.4756569,0.61655504,0.43765485\r\n5618.fused.full.npy.gz,0.49161002,0.63726884,0.46949762\r\n6417.fused.full.npy.gz,0.6446539,0.42772424,0.54589576\r\n9124.fused.full.npy.gz,0.4848227,0.9843533,0.60727453\r\n3162.fused.full.npy.gz,0.36889416,0.40270263,0.45821857\r\n8555.fused.full.npy.gz,0.50735265,0.36146688,0.5046866\r\n4700.fused.full.npy.gz,0.56650805,0.66386634,0.5301286\r\n6072.fused.full.npy.gz,0.81137085,0.79119307,0.6898216\r\n2045.fused.full.npy.gz,0.6526612,0.73312557,0.64522314\r\n6207.fused.full.npy.gz,0.5137296,0.7755575,0.73324466\r\n1582.fused.full.npy.gz,0.61412144,0.44059068,0.5191115\r\n5974.fused.full.npy.gz,0.42673546,0.9088978,0.47408426\r\n3415.fused.full.npy.gz,0.38936368,0.43023968,0.4190189\r\n1240.fused.full.npy.gz,0.66904974,0.951262,0.36797786\r\n3860.fused.full.npy.gz,0.6492002,0.87196124,0.5105098\r\n7863.fused.full.npy.gz,0.6956967,0.7903679,0.59918016\r\n6439.fused.full.npy.gz,0.64563847,0.7121424,0.5331567\r\n3217.fused.full.npy.gz,0.34143013,0.30913866,0.3606669\r\n7411.fused.full.npy.gz,0.5782366,0.90461856,0.58529985\r\n7027.fused.full.npy.gz,0.42354828,0.7454987,0.50257677\r\n7112.fused.full.npy.gz,0.7149662,0.7246187,0.49148363\r\n3878.fused.full.npy.gz,0.6344626,0.84586924,0.5321287\r\n1620.fused.full.npy.gz,0.4926629,0.31247395,0.46314728\r\n7534.fused.full.npy.gz,0.5854858,0.8129667,0.48001486\r\n8479.fused.full.npy.gz,0.5571277,0.6200134,0.64496624\r\n8955.fused.full.npy.gz,0.527637,0.8967259,0.43655384\r\n9557.fused.full.npy.gz,0.61713886,0.9375707,0.46665996\r\n8756.fused.full.npy.gz,0.6143327,0.7489353,0.44051766\r\n7476.fused.full.npy.gz,0.55626696,0.80909467,0.5258266\r\n8932.fused.full.npy.gz,0.47016257,0.90853816,0.45162478\r\n4086.fused.full.npy.gz,0.5804962,0.7703163,0.64068806\r\n7457.fused.full.npy.gz,0.581198,0.6295029,0.5113996\r\n5514.fused.full.npy.gz,0.49327368,0.75689864,0.68504083\r\n5094.fused.full.npy.gz,0.5163723,0.44980687,0.50609106\r\n3040.fused.full.npy.gz,0.34893212,0.31159556,0.5303916\r\n7023.fused.full.npy.gz,0.64493656,0.97636044,0.49092016\r\n6318.fused.full.npy.gz,0.574939,0.5770411,0.54873073\r\n6927.fused.full.npy.gz,0.6083741,0.8504815,0.48035753\r\n8651.fused.full.npy.gz,0.43889484,0.4799633,0.6038594\r\n8359.fused.full.npy.gz,0.6197599,0.5899853,0.73947555\r\n9697.fused.full.npy.gz,0.5067237,0.72734064,0.49814102\r\n5683.fused.full.npy.gz,0.65312994,0.9910748,0.45999557\r\n4207.fused.full.npy.gz,0.52266383,0.6951846,0.65470004\r\n1311.fused.full.npy.gz,0.6888442,0.7829226,0.5567561\r\n9636.fused.full.npy.gz,0.56639636,0.9457042,0.42704326\r\n7900.fused.full.npy.gz,0.7570329,0.97530377,0.4905551\r\n6907.fused.full.npy.gz,0.56696784,0.9103047,0.47383645\r\n2296.fused.full.npy.gz,0.4484191,0.4808175,0.5293936\r\n3079.fused.full.npy.gz,0.5314654,0.5662609,0.6169642\r\n7034.fused.full.npy.gz,0.4438614,0.7603203,0.49265862\r\n3760.fused.full.npy.gz,0.7316438,0.85218114,0.5093513\r\n8664.fused.full.npy.gz,0.4825567,0.46303523,0.65778625\r\n6838.fused.full.npy.gz,0.5961579,1.0020996,0.4311031\r\n4783.fused.full.npy.gz,0.49476665,0.5718593,0.53789884\r\n4537.fused.full.npy.gz,0.4259068,0.6030283,0.7084228\r\n5131.fused.full.npy.gz,0.4926552,0.7012657,0.5898351\r\n4668.fused.full.npy.gz,0.34353602,0.3649993,0.55561686\r\n3751.fused.full.npy.gz,0.7438278,0.9676875,0.6375064\r\n5643.fused.full.npy.gz,0.5128759,0.16899367,0.51833564\r\n6459.fused.full.npy.gz,0.41833773,0.94854283,0.4718984\r\n8467.fused.full.npy.gz,0.5491004,0.69984174,0.63098395\r\n6234.fused.full.npy.gz,0.6059896,0.5425056,0.5016051\r\n3761.fused.full.npy.gz,0.51115555,0.5398449,0.59568936\r\n1904.fused.full.npy.gz,0.6724119,0.70166993,0.6463939\r\n5061.fused.full.npy.gz,0.53920364,0.4505614,0.41963738\r\n8267.fused.full.npy.gz,0.57937217,0.96635485,0.5184705\r\n7510.fused.full.npy.gz,0.71054065,0.9598073,0.5606002\r\n3638.fused.full.npy.gz,0.554145,0.90212613,0.62126654\r\n9705.fused.full.npy.gz,0.5178925,0.74326146,0.54530424\r\n8072.fused.full.npy.gz,0.47986156,0.751465,0.5075649\r\n1788.fused.full.npy.gz,0.6050147,0.55995405,0.5445965\r\n1252.fused.full.npy.gz,0.5103152,0.6927348,0.42727607\r\n5775.fused.full.npy.gz,0.5791031,0.6842985,0.5743927\r\n9558.fused.full.npy.gz,0.4707872,0.75820345,0.56060845\r\n3253.fused.full.npy.gz,0.46733055,0.4421392,0.4935962\r\n2652.fused.full.npy.gz,0.65304613,0.549698,0.6305383\r\n7385.fused.full.npy.gz,0.60921013,0.5615578,0.582431\r\n4883.fused.full.npy.gz,0.400814,0.33212042,0.4222888\r\n5022.fused.full.npy.gz,0.4337076,0.3623132,0.53047454\r\n7094.fused.full.npy.gz,0.52634406,0.339819,0.502103\r\n7563.fused.full.npy.gz,0.56604266,0.91933125,0.44209838\r\n1665.fused.full.npy.gz,0.5458249,0.43848795,0.5023517\r\n2150.fused.full.npy.gz,0.50965035,0.542886,0.6682624\r\n9125.fused.full.npy.gz,0.4854461,0.98331916,0.4618001\r\n2529.fused.full.npy.gz,0.5071446,0.569581,0.67491287\r\n3734.fused.full.npy.gz,0.37287435,0.7758199,0.6278916\r\n2273.fused.full.npy.gz,0.69364274,0.6728982,0.714694\r\n6757.fused.full.npy.gz,0.53106904,0.6594156,0.5884489\r\n2271.fused.full.npy.gz,0.5372755,0.7898531,0.595962\r\n1448.fused.full.npy.gz,0.5538365,0.6462934,0.61544955\r\n6711.fused.full.npy.gz,0.5651572,0.657868,0.6170224\r\n1531.fused.full.npy.gz,0.4378562,0.35065007,0.3810603\r\n1544.fused.full.npy.gz,0.4209387,0.27407777,0.5442266\r\n7058.fused.full.npy.gz,0.5065477,0.67323285,0.5255047\r\n5986.fused.full.npy.gz,0.49563202,0.91468257,0.45692658\r\n9825.fused.full.npy.gz,0.5683347,0.7710819,0.4665498\r\n5645.fused.full.npy.gz,0.44776472,0.58557594,0.49494174\r\n2167.fused.full.npy.gz,0.5453819,0.7800383,0.6107107\r\n2563.fused.full.npy.gz,0.56469566,0.83666617,0.4203876\r\n6723.fused.full.npy.gz,0.4684622,0.68353707,0.44441444\r\n3768.fused.full.npy.gz,0.60836625,0.8547621,0.62005776\r\n5529.fused.full.npy.gz,0.58722365,0.25603592,0.52282137\r\n4566.fused.full.npy.gz,0.77313566,0.6745163,0.76325357\r\n8588.fused.full.npy.gz,0.5001161,0.766436,0.6063543\r\n3308.fused.full.npy.gz,0.39172673,0.63372225,0.6514846\r\n6958.fused.full.npy.gz,0.48390117,0.76029205,0.48903778\r\n5870.fused.full.npy.gz,0.57556653,0.77541715,0.44659278\r\n1956.fused.full.npy.gz,0.6957816,0.78177494,0.5813827\r\n2164.fused.full.npy.gz,0.39313287,0.51447886,0.35625392\r\n2891.fused.full.npy.gz,0.6698319,0.655916,0.6835974\r\n4951.fused.full.npy.gz,0.6935314,0.4138252,0.35787717\r\n5177.fused.full.npy.gz,0.5219835,0.42476934,0.5173434\r\n9673.fused.full.npy.gz,0.60348856,0.77010775,0.47902775\r\n4900.fused.full.npy.gz,0.66151774,0.7603152,0.5650156\r\n8941.fused.full.npy.gz,0.5527334,1.0690649,0.38226658\r\n8892.fused.full.npy.gz,0.5706556,1.0304768,0.45393088\r\n5070.fused.full.npy.gz,0.62795985,0.4185161,0.52852875\r\n1101.fused.full.npy.gz,0.6160996,0.712681,0.4652179\r\n3207.fused.full.npy.gz,0.5204673,0.6080297,0.82251215\r\n,0.6124907,0.8124948\r\n5969.fused.full.npy.gz,0.47082445,0.6788772,0.6539792\r\n4293.fused.full.npy.gz,0.4728907,0.6169385,0.53687537\r\n8769.fused.full.npy.gz,0.45389822,0.8820025,0.42881036\r\n3008.fused.full.npy.gz,0.43291214,0.45123017,0.61700803\r\n8325.fused.full.npy.gz,0.42600948,0.7283042,0.6162193\r\n7886.fused.full.npy.gz,0.63598263,0.68162894,0.48057228\r\n5528.fused.full.npy.gz,0.49344215,0.31237036,0.45009682\r\n1461.fused.full.npy.gz,0.4404171,0.28598487,0.41934383\r\n6544.fused.full.npy.gz,0.76077557,0.9197048,0.5470093\r\n8527.fused.full.npy.gz,0.47110596,0.6019876,0.55402243\r\n1879.fused.full.npy.gz,0.42251235,0.28560865,0.47781482\r\n5410.fused.full.npy.gz,0.40013674,0.5917421,0.60221267\r\n8273.fused.full.npy.gz,0.5713079,0.9264612,0.54970884\r\n4738.fused.full.npy.gz,0.55049914,0.40348834,0.527788\r\n6347.fused.full.npy.gz,0.6274191,0.87742764,0.4072637\r\n6067.fused.full.npy.gz,0.6333318,0.7625738,0.49516743\r\n7074.fused.full.npy.gz,0.50602376,0.9416096,0.428362\r\n2013.fused.full.npy.gz,0.6609142,0.8967277,0.5722954\r\n4515.fused.full.npy.gz,0.57656014,0.6964833,0.63573\r\n9092.fused.full.npy.gz,0.44489723,0.927575,0.5125524\r\n9561.fused.full.npy.gz,0.49525297,0.7435112,0.56370175\r\n1973.fused.full.npy.gz,0.6343291,0.5711135,0.59466773\r\n5923.fused.full.npy.gz,0.41407645,0.35606724,0.47389913\r\n7734.fused.full.npy.gz,0.6870853,0.57397145,0.5691087\r\n1776.fused.full.npy.gz,0.42994055,0.27169454,0.48758096\r\n5885.fused.full.npy.gz,0.6200937,0.7536006,0.66560775\r\n4549.fused.full.npy.gz,0.59712934,0.72285855,0.8270048\r\n3338.fused.full.npy.gz,0.48931393,0.9653971,0.48222917\r\n8860.fused.full.npy.gz,0.45855618,0.7825177,0.49971902\r\n6253.fused.full.npy.gz,0.49370295,0.6681689,0.6490792\r\n4465.fused.full.npy.gz,0.55579686,0.70937663,0.62352854\r\n4501.fused.full.npy.gz,0.5430759,0.6737647,0.6493399\r\n8781.fused.full.npy.gz,0.54104924,0.9412739,0.411684\r\n7258.fused.full.npy.gz,0.45794708,0.32110673,0.49235964\r\n1133.fused.full.npy.gz,0.6446569,0.6612163,0.52451193\r\n4415.fused.full.npy.gz,0.7232932,0.53603315,0.65377444\r\n9853.fused.full.npy.gz,0.61621,0.8687646,0.45569697\r\n2716.fused.full.npy.gz,0.5600352,0.785217,0.7421203\r\n8621.fused.full.npy.gz,0.654919,0.8362007,0.6025118\r\n7659.fused.full.npy.gz,0.53693986,0.849705,0.5308931\r\n2161.fused.full.npy.gz,0.56638044,0.73540074,0.6878717\r\n2514.fused.full.npy.gz,0.64023745,0.6178105,0.563195\r\n8473.fused.full.npy.gz,0.45997572,0.7593195,0.28481144\r\n7230.fused.full.npy.gz,0.26973987,0.34614146,0.40920886\r\n7862.fused.full.npy.gz,0.6081724,0.8654868,0.54721934\r\n1504.fused.full.npy.gz,0.45572624,0.3581444,0.5408312\r\n4869.fused.full.npy.gz,0.5547402,0.2829007,0.4162827\r\n2086.fused.full.npy.gz,0.62392664,0.8150199,0.5201209\r\n4385.fused.full.npy.gz,0.5331874,0.44397044,0.5781161\r\n9596.fused.full.npy.gz,0.59295964,0.75509655,0.587541\r\n3428.fused.full.npy.gz,0.49980763,0.8167589,0.49210596\r\n5086.fused.full.npy.gz,0.5057961,0.5751842,0.5707115\r\n3360.fused.full.npy.gz,0.63200164,0.45813948,0.6519493\r\n9494.fused.full.npy.gz,0.50767887,0.7940712,0.5024795\r\n9583.fused.full.npy.gz,0.57968813,0.9293971,0.47290707\r\n6909.fused.full.npy.gz,0.575029,1.0435865,0.39356348\r\n4817.fused.full.npy.gz,0.42082214,0.37871182,0.61464673\r\n8151.fused.full.npy.gz,0.49487746,0.9600388,0.5048378\r\n7409.fused.full.npy.gz,0.41459692,0.6707987,0.56664026\r\n2152.fused.full.npy.gz,0.45455453,0.4944526,0.6478744\r\n9757.fused.full.npy.gz,0.47258648,0.6271912,0.5513123\r\n5562.fused.full.npy.gz,0.63428175,0.84921783,0.5055752\r\n4593.fused.full.npy.gz,0.36501327,0.31223804,0.39672792\r\n5765.fused.full.npy.gz,0.5916873,0.47231936,0.698881\r\n6713.fused.full.npy.gz,0.51217663,0.5070876,0.54457486\r\n2846.fused.full.npy.gz,0.7252276,0.7738581,0.5364688\r\n3894.fused.full.npy.gz,0.72501266,0.92184305,0.556896\r\n2735.fused.full.npy.gz,0.6041285,0.73869485,0.5831488\r\n9128.fused.full.npy.gz,0.49477005,1.0206233,0.49863225\r\n5095.fused.full.npy.gz,0.7185068,0.575857,0.5050851\r\n5149.fused.full.npy.gz,0.49739486,0.28793567,0.48397425\r\n4061.fused.full.npy.gz,0.56472594,0.65711015,0.49494883\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "268b95a3edb1a18f3255021bc2325740a9db5cb2"
      },
      "cell_type": "code",
      "source": "validation_loader = DataLoader(MultitaskDataset('../input/data/data/multitask_dataset/', train=True, class_mapping=None, max_length=-1), batch_size=45)",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "238ee25d8e4f08f7385807591f13cc81df4f0465"
      },
      "cell_type": "code",
      "source": "vale_pred = []\nene_pred = []\ndance_pred = []\nvale_labels = []\nene_labels = []\ndance_labels = []\nfor j, data_test in enumerate(validation_loader):\n    #print(j)\n    features = torch.tensor(data_test[0]).float().cuda()\n    vale_labels.append(data_test[1])\n    ene_labels.append(data_test[2])\n    dance_labels.append(data_test[3])\n    #labels_val = torch.tensor(data_test[task]).float().cuda()\n    #print(data_test.shape[0])\n    batch_pred1, _ = eval_pred(features, model1)\n    features = torch.tensor(data_test[0]).float().cuda()\n    batch_pred2, _ = eval_pred(features, model2)\n    features = torch.tensor(data_test[0]).float().cuda()\n    batch_pred3, _ = eval_pred(features, model3)\n    vale_pred.append(batch_pred1.cpu().numpy())\n    ene_pred.append(batch_pred2.cpu().numpy())\n    dance_pred.append(batch_pred3.cpu().numpy())\n",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b3fa8f6385376c4f531c8bb0a9052d32105779f"
      },
      "cell_type": "code",
      "source": "flt_vale_labels = [item for sublist in vale_labels for item in sublist]\nflt_ene_labels = [item for sublist in ene_labels for item in sublist]\nflt_dance_labels = [item for sublist in dance_labels for item in sublist]\nflt_vale_preds = [item for sublist in vale_pred for item in sublist]\nflt_dance_preds = [item for sublist in dance_pred for item in sublist]\nflt_ene_preds = [item for sublist in ene_pred for item in sublist]",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[tensor(0.5780, dtype=torch.float64), tensor(0.8390, dtype=torch.float64), tensor(0.5870, dtype=torch.float64), tensor(0.2220, dtype=torch.float64), tensor(0.5760, dtype=torch.float64), tensor(0.5950, dtype=torch.float64), tensor(0.5570, dtype=torch.float64), tensor(0.3640, dtype=torch.float64), tensor(0.8900, dtype=torch.float64), tensor(0.7160, dtype=torch.float64), tensor(0.6990, dtype=torch.float64), tensor(0.1880, dtype=torch.float64), tensor(0.9020, dtype=torch.float64), tensor(0.8660, dtype=torch.float64), tensor(0.7430, dtype=torch.float64), tensor(0.7790, dtype=torch.float64), tensor(0.0702, dtype=torch.float64), tensor(0.3550, dtype=torch.float64), tensor(0.8580, dtype=torch.float64), tensor(0.0859, dtype=torch.float64), tensor(0.7590, dtype=torch.float64), tensor(0.7950, dtype=torch.float64), tensor(0.5610, dtype=torch.float64), tensor(0.1730, dtype=torch.float64), tensor(0.7840, dtype=torch.float64), tensor(0.4540, dtype=torch.float64), tensor(0.8210, dtype=torch.float64), tensor(0.2900, dtype=torch.float64), tensor(0.5610, dtype=torch.float64), tensor(0.5610, dtype=torch.float64), tensor(0.9110, dtype=torch.float64), tensor(0.8460, dtype=torch.float64), tensor(0.8540, dtype=torch.float64), tensor(0.5410, dtype=torch.float64), tensor(0.2570, dtype=torch.float64), tensor(0.7230, dtype=torch.float64), tensor(0.4910, dtype=torch.float64), tensor(0.8480, dtype=torch.float64), tensor(0.0687, dtype=torch.float64), tensor(0.8360, dtype=torch.float64), tensor(0.2520, dtype=torch.float64), tensor(0.8150, dtype=torch.float64), tensor(0.7650, dtype=torch.float64), tensor(0.5380, dtype=torch.float64), tensor(0.2130, dtype=torch.float64), tensor(0.7650, dtype=torch.float64), tensor(0.2880, dtype=torch.float64), tensor(0.8780, dtype=torch.float64), tensor(0.5580, dtype=torch.float64), tensor(0.0766, dtype=torch.float64), tensor(0.3300, dtype=torch.float64), tensor(0.6290, dtype=torch.float64), tensor(0.3520, dtype=torch.float64), tensor(0.1410, dtype=torch.float64), tensor(0.6450, dtype=torch.float64), tensor(0.7050, dtype=torch.float64), tensor(0.7670, dtype=torch.float64), tensor(0.4320, dtype=torch.float64), tensor(0.2370, dtype=torch.float64), tensor(0.1470, dtype=torch.float64), tensor(0.1510, dtype=torch.float64), tensor(0.6110, dtype=torch.float64), tensor(0.2730, dtype=torch.float64), tensor(0.6530, dtype=torch.float64), tensor(0.8440, dtype=torch.float64), tensor(0.5590, dtype=torch.float64), tensor(0.8640, dtype=torch.float64), tensor(0.6020, dtype=torch.float64), tensor(0.7470, dtype=torch.float64), tensor(0.8110, dtype=torch.float64), tensor(0.3910, dtype=torch.float64), tensor(0.5170, dtype=torch.float64), tensor(0.5300, dtype=torch.float64), tensor(0.9000, dtype=torch.float64), tensor(0.5900, dtype=torch.float64), tensor(0.8910, dtype=torch.float64), tensor(0.6940, dtype=torch.float64), tensor(0.7160, dtype=torch.float64), tensor(0.3620, dtype=torch.float64), tensor(0.3070, dtype=torch.float64), tensor(0.8270, dtype=torch.float64), tensor(0.3620, dtype=torch.float64), tensor(0.8520, dtype=torch.float64), tensor(0.3920, dtype=torch.float64), tensor(0.6180, dtype=torch.float64), tensor(0.1520, dtype=torch.float64), tensor(0.9630, dtype=torch.float64), tensor(0.4170, dtype=torch.float64), tensor(0.2990, dtype=torch.float64), tensor(0.4630, dtype=torch.float64), tensor(0.1320, dtype=torch.float64), tensor(0.4060, dtype=torch.float64), tensor(0.0684, dtype=torch.float64), tensor(0.7590, dtype=torch.float64), tensor(0.3180, dtype=torch.float64), tensor(0.6820, dtype=torch.float64), tensor(0.8350, dtype=torch.float64), tensor(0.3640, dtype=torch.float64), tensor(0.2700, dtype=torch.float64), tensor(0.7430, dtype=torch.float64), tensor(0.5920, dtype=torch.float64), tensor(0.3520, dtype=torch.float64), tensor(0.2320, dtype=torch.float64), tensor(0.4400, dtype=torch.float64), tensor(0.7980, dtype=torch.float64), tensor(0.6090, dtype=torch.float64), tensor(0.5400, dtype=torch.float64), tensor(0.1070, dtype=torch.float64), tensor(0.5270, dtype=torch.float64), tensor(0.3210, dtype=torch.float64), tensor(0.6190, dtype=torch.float64), tensor(0.5910, dtype=torch.float64), tensor(0.4780, dtype=torch.float64), tensor(0.4580, dtype=torch.float64), tensor(0.8570, dtype=torch.float64), tensor(0.1480, dtype=torch.float64), tensor(0.3290, dtype=torch.float64), tensor(0.9220, dtype=torch.float64), tensor(0.5390, dtype=torch.float64), tensor(0.9010, dtype=torch.float64), tensor(0.7330, dtype=torch.float64), tensor(0.4930, dtype=torch.float64), tensor(0.9580, dtype=torch.float64), tensor(0.8160, dtype=torch.float64), tensor(0.1530, dtype=torch.float64), tensor(0.5970, dtype=torch.float64), tensor(0.0765, dtype=torch.float64), tensor(0.3380, dtype=torch.float64), tensor(0.6080, dtype=torch.float64), tensor(0.9280, dtype=torch.float64), tensor(0.9290, dtype=torch.float64), tensor(0.1830, dtype=torch.float64), tensor(0.4810, dtype=torch.float64), tensor(0.5350, dtype=torch.float64), tensor(0.5580, dtype=torch.float64), tensor(0.4700, dtype=torch.float64), tensor(0.5950, dtype=torch.float64), tensor(0.9100, dtype=torch.float64), tensor(0.7780, dtype=torch.float64), tensor(0.2040, dtype=torch.float64), tensor(0.6410, dtype=torch.float64), tensor(0.0732, dtype=torch.float64), tensor(0.5360, dtype=torch.float64), tensor(0.7290, dtype=torch.float64), tensor(0.7730, dtype=torch.float64), tensor(0.3180, dtype=torch.float64), tensor(0.7150, dtype=torch.float64), tensor(0.7820, dtype=torch.float64), tensor(0.7110, dtype=torch.float64), tensor(0.6710, dtype=torch.float64), tensor(0.6720, dtype=torch.float64), tensor(0.4800, dtype=torch.float64), tensor(0.9650, dtype=torch.float64), tensor(0.8560, dtype=torch.float64), tensor(0.2330, dtype=torch.float64), tensor(0.6090, dtype=torch.float64), tensor(0.6210, dtype=torch.float64), tensor(0.8050, dtype=torch.float64), tensor(0.8730, dtype=torch.float64), tensor(0.7580, dtype=torch.float64), tensor(0.7210, dtype=torch.float64), tensor(0.8730, dtype=torch.float64), tensor(0.2430, dtype=torch.float64), tensor(0.1040, dtype=torch.float64), tensor(0.1480, dtype=torch.float64), tensor(0.9670, dtype=torch.float64), tensor(0.3050, dtype=torch.float64), tensor(0.2570, dtype=torch.float64), tensor(0.4970, dtype=torch.float64), tensor(0.0936, dtype=torch.float64), tensor(0.6500, dtype=torch.float64), tensor(0.7580, dtype=torch.float64), tensor(0.5400, dtype=torch.float64), tensor(0.0848, dtype=torch.float64), tensor(0.8390, dtype=torch.float64), tensor(0.8000, dtype=torch.float64), tensor(0.6430, dtype=torch.float64), tensor(0.6590, dtype=torch.float64), tensor(0.7400, dtype=torch.float64), tensor(0.1020, dtype=torch.float64), tensor(0.6570, dtype=torch.float64), tensor(0.2030, dtype=torch.float64), tensor(0.3580, dtype=torch.float64), tensor(0.2300, dtype=torch.float64), tensor(0.6060, dtype=torch.float64), tensor(0.8120, dtype=torch.float64), tensor(0.2160, dtype=torch.float64), tensor(0.5810, dtype=torch.float64), tensor(0.3730, dtype=torch.float64), tensor(0.5000, dtype=torch.float64), tensor(0.5670, dtype=torch.float64), tensor(0.6440, dtype=torch.float64), tensor(0.8040, dtype=torch.float64), tensor(0.5600, dtype=torch.float64), tensor(0.6610, dtype=torch.float64), tensor(0.8180, dtype=torch.float64), tensor(0.8210, dtype=torch.float64), tensor(0.1110, dtype=torch.float64), tensor(0.5160, dtype=torch.float64), tensor(0.1700, dtype=torch.float64), tensor(0.7590, dtype=torch.float64), tensor(0.8510, dtype=torch.float64), tensor(0.4150, dtype=torch.float64), tensor(0.7270, dtype=torch.float64), tensor(0.7100, dtype=torch.float64), tensor(0.4100, dtype=torch.float64), tensor(0.8180, dtype=torch.float64), tensor(0.7360, dtype=torch.float64), tensor(0.9460, dtype=torch.float64), tensor(0.7380, dtype=torch.float64), tensor(0.6270, dtype=torch.float64), tensor(0.3590, dtype=torch.float64), tensor(0.1200, dtype=torch.float64), tensor(0.1770, dtype=torch.float64), tensor(0.4330, dtype=torch.float64), tensor(0.7970, dtype=torch.float64), tensor(0.3020, dtype=torch.float64), tensor(0.6180, dtype=torch.float64), tensor(0.7880, dtype=torch.float64), tensor(0.4560, dtype=torch.float64), tensor(0.1090, dtype=torch.float64), tensor(0.2850, dtype=torch.float64), tensor(0.6710, dtype=torch.float64), tensor(0.8430, dtype=torch.float64), tensor(0.4460, dtype=torch.float64), tensor(0.7670, dtype=torch.float64), tensor(0.8560, dtype=torch.float64), tensor(0.4560, dtype=torch.float64), tensor(0.6190, dtype=torch.float64), tensor(0.4890, dtype=torch.float64), tensor(0.8850, dtype=torch.float64), tensor(0.8810, dtype=torch.float64), tensor(0.3830, dtype=torch.float64), tensor(0.4980, dtype=torch.float64), tensor(0.3430, dtype=torch.float64), tensor(0.4730, dtype=torch.float64), tensor(0.2360, dtype=torch.float64), tensor(0.7880, dtype=torch.float64), tensor(0.0707, dtype=torch.float64), tensor(0.6890, dtype=torch.float64), tensor(0.5930, dtype=torch.float64), tensor(0.1470, dtype=torch.float64), tensor(0.6130, dtype=torch.float64), tensor(0.7070, dtype=torch.float64), tensor(0.9220, dtype=torch.float64), tensor(0.8340, dtype=torch.float64), tensor(0.3020, dtype=torch.float64), tensor(0.9540, dtype=torch.float64), tensor(0.9730, dtype=torch.float64), tensor(0.7030, dtype=torch.float64), tensor(0.5130, dtype=torch.float64), tensor(0.9180, dtype=torch.float64), tensor(0.3120, dtype=torch.float64), tensor(0.8730, dtype=torch.float64), tensor(0.6290, dtype=torch.float64), tensor(0.2450, dtype=torch.float64), tensor(0.4770, dtype=torch.float64), tensor(0.3980, dtype=torch.float64), tensor(0.6260, dtype=torch.float64), tensor(0.0454, dtype=torch.float64), tensor(0.9420, dtype=torch.float64), tensor(0.5430, dtype=torch.float64), tensor(0.6240, dtype=torch.float64), tensor(0.3440, dtype=torch.float64), tensor(0.5170, dtype=torch.float64), tensor(0.3970, dtype=torch.float64), tensor(0.2390, dtype=torch.float64), tensor(0.9680, dtype=torch.float64), tensor(0.7880, dtype=torch.float64), tensor(0.3580, dtype=torch.float64), tensor(0.8820, dtype=torch.float64), tensor(0.3530, dtype=torch.float64), tensor(0.6730, dtype=torch.float64), tensor(0.1700, dtype=torch.float64), tensor(0.5060, dtype=torch.float64), tensor(0.4860, dtype=torch.float64), tensor(0.1140, dtype=torch.float64), tensor(0.1160, dtype=torch.float64), tensor(0.4420, dtype=torch.float64), tensor(0.8090, dtype=torch.float64), tensor(0.2070, dtype=torch.float64), tensor(0.2290, dtype=torch.float64), tensor(0.6090, dtype=torch.float64), tensor(0.4900, dtype=torch.float64), tensor(0.1510, dtype=torch.float64), tensor(0.1720, dtype=torch.float64), tensor(0.0393, dtype=torch.float64), tensor(0.5720, dtype=torch.float64), tensor(0.6810, dtype=torch.float64), tensor(0.3890, dtype=torch.float64), tensor(0.7640, dtype=torch.float64), tensor(0.5020, dtype=torch.float64), tensor(0.3680, dtype=torch.float64), tensor(0.9490, dtype=torch.float64), tensor(0.6270, dtype=torch.float64), tensor(0.0648, dtype=torch.float64), tensor(0.1670, dtype=torch.float64), tensor(0.4290, dtype=torch.float64), tensor(0.8870, dtype=torch.float64), tensor(0.5270, dtype=torch.float64), tensor(0.3730, dtype=torch.float64), tensor(0.8650, dtype=torch.float64), tensor(0.7340, dtype=torch.float64), tensor(0.2580, dtype=torch.float64), tensor(0.5910, dtype=torch.float64), tensor(0.7170, dtype=torch.float64), tensor(0.8360, dtype=torch.float64), tensor(0.6310, dtype=torch.float64), tensor(0.3480, dtype=torch.float64), tensor(0.2150, dtype=torch.float64), tensor(0.1360, dtype=torch.float64), tensor(0.2400, dtype=torch.float64), tensor(0.8020, dtype=torch.float64), tensor(0.5990, dtype=torch.float64), tensor(0.6810, dtype=torch.float64), tensor(0.2540, dtype=torch.float64), tensor(0.0925, dtype=torch.float64), tensor(0.7410, dtype=torch.float64), tensor(0.2410, dtype=torch.float64), tensor(0.1040, dtype=torch.float64), tensor(0.0748, dtype=torch.float64), tensor(0.4390, dtype=torch.float64), tensor(0.3420, dtype=torch.float64), tensor(0.3360, dtype=torch.float64), tensor(0.1560, dtype=torch.float64), tensor(0.3600, dtype=torch.float64), tensor(0.5450, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1240, dtype=torch.float64), tensor(0.3150, dtype=torch.float64), tensor(0.9650, dtype=torch.float64), tensor(0.2440, dtype=torch.float64), tensor(0.2550, dtype=torch.float64), tensor(0.8230, dtype=torch.float64), tensor(0.2690, dtype=torch.float64), tensor(0.6700, dtype=torch.float64), tensor(0.2710, dtype=torch.float64), tensor(0.6230, dtype=torch.float64), tensor(0.7350, dtype=torch.float64), tensor(0.4940, dtype=torch.float64), tensor(0.5130, dtype=torch.float64), tensor(0.3650, dtype=torch.float64), tensor(0.3210, dtype=torch.float64), tensor(0.8140, dtype=torch.float64), tensor(0.2340, dtype=torch.float64), tensor(0.2160, dtype=torch.float64), tensor(0.1510, dtype=torch.float64), tensor(0.4040, dtype=torch.float64), tensor(0.3590, dtype=torch.float64), tensor(0.5470, dtype=torch.float64), tensor(0.3730, dtype=torch.float64), tensor(0.5520, dtype=torch.float64), tensor(0.7080, dtype=torch.float64), tensor(0.1910, dtype=torch.float64), tensor(0.3290, dtype=torch.float64), tensor(0.0443, dtype=torch.float64), tensor(0.6190, dtype=torch.float64), tensor(0.3800, dtype=torch.float64), tensor(0.5690, dtype=torch.float64), tensor(0.7890, dtype=torch.float64), tensor(0.3340, dtype=torch.float64), tensor(0.6580, dtype=torch.float64), tensor(0.6830, dtype=torch.float64), tensor(0.8140, dtype=torch.float64), tensor(0.7160, dtype=torch.float64), tensor(0.4030, dtype=torch.float64), tensor(0.0479, dtype=torch.float64), tensor(0.9050, dtype=torch.float64), tensor(0.7790, dtype=torch.float64), tensor(0.5810, dtype=torch.float64), tensor(0.4700, dtype=torch.float64), tensor(0.7940, dtype=torch.float64), tensor(0.2640, dtype=torch.float64), tensor(0.3600, dtype=torch.float64), tensor(0.3920, dtype=torch.float64), tensor(0.0564, dtype=torch.float64), tensor(0.6470, dtype=torch.float64), tensor(0.4030, dtype=torch.float64), tensor(0.3270, dtype=torch.float64), tensor(0.9620, dtype=torch.float64), tensor(0.8360, dtype=torch.float64), tensor(0.6330, dtype=torch.float64), tensor(0.8290, dtype=torch.float64), tensor(0.8960, dtype=torch.float64), tensor(0.6820, dtype=torch.float64), tensor(0.3500, dtype=torch.float64), tensor(0.3550, dtype=torch.float64), tensor(0.7050, dtype=torch.float64), tensor(0.7060, dtype=torch.float64), tensor(0.3020, dtype=torch.float64), tensor(0.8010, dtype=torch.float64), tensor(0.3780, dtype=torch.float64), tensor(0.8020, dtype=torch.float64), tensor(0.7810, dtype=torch.float64), tensor(0.7060, dtype=torch.float64), tensor(0.8310, dtype=torch.float64), tensor(0.8140, dtype=torch.float64), tensor(0.7890, dtype=torch.float64), tensor(0.6560, dtype=torch.float64), tensor(0.7800, dtype=torch.float64), tensor(0.1890, dtype=torch.float64), tensor(0.4730, dtype=torch.float64), tensor(0.3890, dtype=torch.float64), tensor(0.9630, dtype=torch.float64), tensor(0.9050, dtype=torch.float64), tensor(0.8060, dtype=torch.float64), tensor(0.2370, dtype=torch.float64), tensor(0.2380, dtype=torch.float64), tensor(0.4320, dtype=torch.float64), tensor(0.4030, dtype=torch.float64), tensor(0.8770, dtype=torch.float64), tensor(0.0436, dtype=torch.float64), tensor(0.8670, dtype=torch.float64), tensor(0.5220, dtype=torch.float64), tensor(0.5540, dtype=torch.float64), tensor(0.3020, dtype=torch.float64), tensor(0.6500, dtype=torch.float64), tensor(0.7000, dtype=torch.float64), tensor(0.2070, dtype=torch.float64), tensor(0.0509, dtype=torch.float64), tensor(0.5380, dtype=torch.float64), tensor(0.6280, dtype=torch.float64), tensor(0.2300, dtype=torch.float64), tensor(0.9120, dtype=torch.float64), tensor(0.3340, dtype=torch.float64), tensor(0.9660, dtype=torch.float64), tensor(0.4500, dtype=torch.float64), tensor(0.4890, dtype=torch.float64), tensor(0.7020, dtype=torch.float64), tensor(0.3160, dtype=torch.float64), tensor(0.2610, dtype=torch.float64), tensor(0.0867, dtype=torch.float64), tensor(0.7260, dtype=torch.float64), tensor(0.2640, dtype=torch.float64), tensor(0.2830, dtype=torch.float64), tensor(0.8280, dtype=torch.float64), tensor(0.8730, dtype=torch.float64), tensor(0.5930, dtype=torch.float64), tensor(0.5170, dtype=torch.float64), tensor(0.4230, dtype=torch.float64), tensor(0.2470, dtype=torch.float64), tensor(0.4740, dtype=torch.float64), tensor(0.9500, dtype=torch.float64), tensor(0.9240, dtype=torch.float64), tensor(0.7480, dtype=torch.float64), tensor(0.7310, dtype=torch.float64), tensor(0.7320, dtype=torch.float64), tensor(0.0357, dtype=torch.float64), tensor(0.1850, dtype=torch.float64), tensor(0.8720, dtype=torch.float64), tensor(0.1930, dtype=torch.float64), tensor(0.9610, dtype=torch.float64), tensor(0.5730, dtype=torch.float64), tensor(0.7310, dtype=torch.float64), tensor(0.3530, dtype=torch.float64), tensor(0.7020, dtype=torch.float64), tensor(0.2670, dtype=torch.float64), tensor(0.3330, dtype=torch.float64), tensor(0.5160, dtype=torch.float64), tensor(0.2670, dtype=torch.float64), tensor(0.8230, dtype=torch.float64), tensor(0.6270, dtype=torch.float64), tensor(0.7720, dtype=torch.float64), tensor(0.2130, dtype=torch.float64), tensor(0.0639, dtype=torch.float64), tensor(0.2740, dtype=torch.float64), tensor(0.4530, dtype=torch.float64), tensor(0.7660, dtype=torch.float64), tensor(0.5970, dtype=torch.float64), tensor(0.4780, dtype=torch.float64), tensor(0.9510, dtype=torch.float64), tensor(0.7060, dtype=torch.float64), tensor(0.2460, dtype=torch.float64), tensor(0.3220, dtype=torch.float64), tensor(0.8130, dtype=torch.float64), tensor(0.7650, dtype=torch.float64), tensor(0.8370, dtype=torch.float64), tensor(0.0803, dtype=torch.float64), tensor(0.5680, dtype=torch.float64), tensor(0.4630, dtype=torch.float64), tensor(0.9630, dtype=torch.float64), tensor(0.9520, dtype=torch.float64), tensor(0.7890, dtype=torch.float64), tensor(0.7650, dtype=torch.float64), tensor(0.2710, dtype=torch.float64), tensor(0.1110, dtype=torch.float64), tensor(0.6540, dtype=torch.float64), tensor(0.2390, dtype=torch.float64), tensor(0.9660, dtype=torch.float64), tensor(0.8850, dtype=torch.float64), tensor(0.3860, dtype=torch.float64), tensor(0.8380, dtype=torch.float64), tensor(0.4400, dtype=torch.float64), tensor(0.4540, dtype=torch.float64), tensor(0.8880, dtype=torch.float64), tensor(0.4490, dtype=torch.float64), tensor(0.9370, dtype=torch.float64), tensor(0.9250, dtype=torch.float64), tensor(0.8060, dtype=torch.float64), tensor(0.9180, dtype=torch.float64), tensor(0.7090, dtype=torch.float64), tensor(0.4000, dtype=torch.float64), tensor(0.2210, dtype=torch.float64), tensor(0.6890, dtype=torch.float64), tensor(0.3780, dtype=torch.float64), tensor(0.6640, dtype=torch.float64), tensor(0.3610, dtype=torch.float64), tensor(0.4480, dtype=torch.float64), tensor(0.3000, dtype=torch.float64), tensor(0.7020, dtype=torch.float64), tensor(0.9640, dtype=torch.float64), tensor(0.8840, dtype=torch.float64), tensor(0.9720, dtype=torch.float64), tensor(0.5130, dtype=torch.float64), tensor(0.6150, dtype=torch.float64), tensor(0.3850, dtype=torch.float64), tensor(0.3710, dtype=torch.float64), tensor(0.7110, dtype=torch.float64), tensor(0.9110, dtype=torch.float64), tensor(0.8400, dtype=torch.float64), tensor(0.4900, dtype=torch.float64), tensor(0.1560, dtype=torch.float64), tensor(0.8880, dtype=torch.float64), tensor(0.5360, dtype=torch.float64), tensor(0.3350, dtype=torch.float64), tensor(0.4680, dtype=torch.float64), tensor(0.6870, dtype=torch.float64), tensor(0.5710, dtype=torch.float64), tensor(0.5700, dtype=torch.float64), tensor(0.1780, dtype=torch.float64), tensor(0.9390, dtype=torch.float64), tensor(0.9100, dtype=torch.float64), tensor(0.4620, dtype=torch.float64), tensor(0.2250, dtype=torch.float64), tensor(0.4270, dtype=torch.float64), tensor(0.8570, dtype=torch.float64), tensor(0.4480, dtype=torch.float64), tensor(0.8740, dtype=torch.float64), tensor(0.7890, dtype=torch.float64), tensor(0.8660, dtype=torch.float64), tensor(0.3680, dtype=torch.float64), tensor(0.9220, dtype=torch.float64), tensor(0.6490, dtype=torch.float64), tensor(0.0768, dtype=torch.float64), tensor(0.1980, dtype=torch.float64), tensor(0.7560, dtype=torch.float64), tensor(0.8120, dtype=torch.float64), tensor(0.3000, dtype=torch.float64), tensor(0.6970, dtype=torch.float64), tensor(0.3200, dtype=torch.float64), tensor(0.9690, dtype=torch.float64), tensor(0.9280, dtype=torch.float64), tensor(0.9670, dtype=torch.float64), tensor(0.7770, dtype=torch.float64), tensor(0.4690, dtype=torch.float64), tensor(0.4150, dtype=torch.float64), tensor(0.0391, dtype=torch.float64), tensor(0.7220, dtype=torch.float64), tensor(0.3350, dtype=torch.float64), tensor(0.5350, dtype=torch.float64), tensor(0.2790, dtype=torch.float64), tensor(0.5450, dtype=torch.float64), tensor(0.2370, dtype=torch.float64), tensor(0.4240, dtype=torch.float64), tensor(0.6320, dtype=torch.float64), tensor(0.1780, dtype=torch.float64), tensor(0.4180, dtype=torch.float64), tensor(0.3970, dtype=torch.float64), tensor(0.5310, dtype=torch.float64), tensor(0.7110, dtype=torch.float64), tensor(0.4300, dtype=torch.float64), tensor(0.7570, dtype=torch.float64), tensor(0.2990, dtype=torch.float64), tensor(0.9770, dtype=torch.float64), tensor(0.3520, dtype=torch.float64), tensor(0.1960, dtype=torch.float64), tensor(0.5240, dtype=torch.float64), tensor(0.8180, dtype=torch.float64), tensor(0.4960, dtype=torch.float64), tensor(0.7180, dtype=torch.float64), tensor(0.1200, dtype=torch.float64), tensor(0.3420, dtype=torch.float64), tensor(0.9460, dtype=torch.float64), tensor(0.7570, dtype=torch.float64), tensor(0.4350, dtype=torch.float64), tensor(0.7120, dtype=torch.float64), tensor(0.6890, dtype=torch.float64), tensor(0.9150, dtype=torch.float64), tensor(0.8440, dtype=torch.float64), tensor(0.1440, dtype=torch.float64), tensor(0.5880, dtype=torch.float64), tensor(0.7130, dtype=torch.float64), tensor(0.2720, dtype=torch.float64), tensor(0.8960, dtype=torch.float64), tensor(0.3330, dtype=torch.float64), tensor(0.7070, dtype=torch.float64), tensor(0.4580, dtype=torch.float64), tensor(0.1520, dtype=torch.float64), tensor(0.4100, dtype=torch.float64), tensor(0.3470, dtype=torch.float64), tensor(0.9210, dtype=torch.float64), tensor(0.7560, dtype=torch.float64), tensor(0.0838, dtype=torch.float64), tensor(0.1310, dtype=torch.float64), tensor(0.6790, dtype=torch.float64), tensor(0.4420, dtype=torch.float64), tensor(0.3110, dtype=torch.float64), tensor(0.0615, dtype=torch.float64), tensor(0.7500, dtype=torch.float64), tensor(0.7250, dtype=torch.float64), tensor(0.1690, dtype=torch.float64), tensor(0.0748, dtype=torch.float64), tensor(0.8110, dtype=torch.float64), tensor(0.4980, dtype=torch.float64), tensor(0.6290, dtype=torch.float64), tensor(0.5100, dtype=torch.float64), tensor(0.7920, dtype=torch.float64), tensor(0.1880, dtype=torch.float64), tensor(0.8580, dtype=torch.float64), tensor(0.3770, dtype=torch.float64), tensor(0.7140, dtype=torch.float64), tensor(0.4620, dtype=torch.float64), tensor(0.6770, dtype=torch.float64), tensor(0.5580, dtype=torch.float64), tensor(0.3750, dtype=torch.float64), tensor(0.6820, dtype=torch.float64), tensor(0.6210, dtype=torch.float64), tensor(0.7720, dtype=torch.float64), tensor(0.1620, dtype=torch.float64), tensor(0.1130, dtype=torch.float64), tensor(0.7630, dtype=torch.float64), tensor(0.7240, dtype=torch.float64), tensor(0.9680, dtype=torch.float64), tensor(0.3210, dtype=torch.float64), tensor(0.3470, dtype=torch.float64), tensor(0.9680, dtype=torch.float64), tensor(0.5900, dtype=torch.float64), tensor(0.0399, dtype=torch.float64), tensor(0.7590, dtype=torch.float64), tensor(0.5940, dtype=torch.float64), tensor(0.7570, dtype=torch.float64), tensor(0.3110, dtype=torch.float64), tensor(0.3270, dtype=torch.float64), tensor(0.4360, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.6930, dtype=torch.float64), tensor(0.9370, dtype=torch.float64), tensor(0.4370, dtype=torch.float64), tensor(0.4550, dtype=torch.float64), tensor(0.5290, dtype=torch.float64), tensor(0.7180, dtype=torch.float64), tensor(0.9020, dtype=torch.float64), tensor(0.2200, dtype=torch.float64), tensor(0.5790, dtype=torch.float64), tensor(0.6400, dtype=torch.float64), tensor(0.4940, dtype=torch.float64), tensor(0.3770, dtype=torch.float64), tensor(0.8230, dtype=torch.float64), tensor(0.3500, dtype=torch.float64), tensor(0.7390, dtype=torch.float64), tensor(0.4030, dtype=torch.float64), tensor(0.5660, dtype=torch.float64), tensor(0.9440, dtype=torch.float64), tensor(0.6820, dtype=torch.float64), tensor(0.0393, dtype=torch.float64), tensor(0.3650, dtype=torch.float64), tensor(0.5940, dtype=torch.float64), tensor(0.6740, dtype=torch.float64), tensor(0.6960, dtype=torch.float64), tensor(0.6960, dtype=torch.float64), tensor(0.5330, dtype=torch.float64), tensor(0.1360, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.0930, dtype=torch.float64), tensor(0.8700, dtype=torch.float64), tensor(0.9090, dtype=torch.float64), tensor(0.6390, dtype=torch.float64), tensor(0.4870, dtype=torch.float64), tensor(0.1010, dtype=torch.float64), tensor(0.2120, dtype=torch.float64), tensor(0.5650, dtype=torch.float64), tensor(0.5410, dtype=torch.float64), tensor(0.5780, dtype=torch.float64), tensor(0.8460, dtype=torch.float64), tensor(0.6470, dtype=torch.float64), tensor(0.5840, dtype=torch.float64), tensor(0.7720, dtype=torch.float64), tensor(0.9270, dtype=torch.float64), tensor(0.4540, dtype=torch.float64), tensor(0.6470, dtype=torch.float64), tensor(0.2620, dtype=torch.float64), tensor(0.2480, dtype=torch.float64), tensor(0.9630, dtype=torch.float64), tensor(0.3280, dtype=torch.float64), tensor(0.7330, dtype=torch.float64), tensor(0.4000, dtype=torch.float64), tensor(0.8220, dtype=torch.float64), tensor(0.9150, dtype=torch.float64), tensor(0.8240, dtype=torch.float64), tensor(0.6160, dtype=torch.float64), tensor(0.5060, dtype=torch.float64), tensor(0.1930, dtype=torch.float64), tensor(0.7280, dtype=torch.float64), tensor(0.1690, dtype=torch.float64), tensor(0.4860, dtype=torch.float64), tensor(0.5430, dtype=torch.float64), tensor(0.8050, dtype=torch.float64), tensor(0.5970, dtype=torch.float64), tensor(0.5310, dtype=torch.float64), tensor(0.4340, dtype=torch.float64), tensor(0.1890, dtype=torch.float64), tensor(0.8110, dtype=torch.float64), tensor(0.7160, dtype=torch.float64), tensor(0.6780, dtype=torch.float64), tensor(0.4240, dtype=torch.float64), tensor(0.5410, dtype=torch.float64), tensor(0.5570, dtype=torch.float64), tensor(0.2120, dtype=torch.float64), tensor(0.4060, dtype=torch.float64), tensor(0.9010, dtype=torch.float64), tensor(0.1970, dtype=torch.float64), tensor(0.9020, dtype=torch.float64), tensor(0.9650, dtype=torch.float64), tensor(0.9640, dtype=torch.float64), tensor(0.6870, dtype=torch.float64), tensor(0.8070, dtype=torch.float64), tensor(0.6170, dtype=torch.float64), tensor(0.8270, dtype=torch.float64), tensor(0.0245, dtype=torch.float64), tensor(0.1510, dtype=torch.float64), tensor(0.4530, dtype=torch.float64), tensor(0.6180, dtype=torch.float64), tensor(0.3950, dtype=torch.float64), tensor(0.4530, dtype=torch.float64), tensor(0.8020, dtype=torch.float64), tensor(0.4130, dtype=torch.float64), tensor(0.7720, dtype=torch.float64), tensor(0.3670, dtype=torch.float64), tensor(0.3890, dtype=torch.float64), tensor(0.5840, dtype=torch.float64), tensor(0.6480, dtype=torch.float64), tensor(0.8480, dtype=torch.float64), tensor(0.2360, dtype=torch.float64), tensor(0.5920, dtype=torch.float64), tensor(0.0361, dtype=torch.float64), tensor(0.4170, dtype=torch.float64), tensor(0.8980, dtype=torch.float64), tensor(0.6090, dtype=torch.float64), tensor(0.8450, dtype=torch.float64), tensor(0.2220, dtype=torch.float64), tensor(0.8300, dtype=torch.float64), tensor(0.8910, dtype=torch.float64), tensor(0.2760, dtype=torch.float64), tensor(0.3040, dtype=torch.float64), tensor(0.7710, dtype=torch.float64), tensor(0.4400, dtype=torch.float64), tensor(0.7060, dtype=torch.float64), tensor(0.9520, dtype=torch.float64), tensor(0.6240, dtype=torch.float64), tensor(0.1620, dtype=torch.float64), tensor(0.4990, dtype=torch.float64), tensor(0.1390, dtype=torch.float64), tensor(0.5770, dtype=torch.float64), tensor(0.7840, dtype=torch.float64), tensor(0.1620, dtype=torch.float64), tensor(0.7090, dtype=torch.float64), tensor(0.6610, dtype=torch.float64), tensor(0.9750, dtype=torch.float64), tensor(0.2080, dtype=torch.float64), tensor(0.3930, dtype=torch.float64), tensor(0.3350, dtype=torch.float64), tensor(0.5560, dtype=torch.float64), tensor(0.2510, dtype=torch.float64), tensor(0.8500, dtype=torch.float64), tensor(0.9650, dtype=torch.float64), tensor(0.7420, dtype=torch.float64), tensor(0.5740, dtype=torch.float64), tensor(0.8450, dtype=torch.float64), tensor(0.8610, dtype=torch.float64), tensor(0.3060, dtype=torch.float64), tensor(0.8900, dtype=torch.float64), tensor(0.5820, dtype=torch.float64), tensor(0.6710, dtype=torch.float64), tensor(0.6640, dtype=torch.float64), tensor(0.3340, dtype=torch.float64), tensor(0.4190, dtype=torch.float64), tensor(0.9550, dtype=torch.float64), tensor(0.3320, dtype=torch.float64), tensor(0.3670, dtype=torch.float64), tensor(0.5580, dtype=torch.float64), tensor(0.7450, dtype=torch.float64), tensor(0.5220, dtype=torch.float64), tensor(0.0967, dtype=torch.float64), tensor(0.8220, dtype=torch.float64), tensor(0.8720, dtype=torch.float64), tensor(0.7310, dtype=torch.float64), tensor(0.8060, dtype=torch.float64), tensor(0.1320, dtype=torch.float64), tensor(0.3820, dtype=torch.float64), tensor(0.8380, dtype=torch.float64), tensor(0.1960, dtype=torch.float64), tensor(0.4090, dtype=torch.float64), tensor(0.5480, dtype=torch.float64), tensor(0.1220, dtype=torch.float64), tensor(0.7020, dtype=torch.float64), tensor(0.8080, dtype=torch.float64), tensor(0.4560, dtype=torch.float64), tensor(0.2290, dtype=torch.float64), tensor(0.7500, dtype=torch.float64), tensor(0.3230, dtype=torch.float64), tensor(0.6880, dtype=torch.float64), tensor(0.6990, dtype=torch.float64), tensor(0.2170, dtype=torch.float64), tensor(0.2480, dtype=torch.float64), tensor(0.2540, dtype=torch.float64), tensor(0.2240, dtype=torch.float64), tensor(0.6690, dtype=torch.float64), tensor(0.3320, dtype=torch.float64), tensor(0.4920, dtype=torch.float64), tensor(0.7620, dtype=torch.float64), tensor(0.4780, dtype=torch.float64), tensor(0.7500, dtype=torch.float64), tensor(0.6880, dtype=torch.float64), tensor(0.0874, dtype=torch.float64), tensor(0.6510, dtype=torch.float64), tensor(0.5640, dtype=torch.float64), tensor(0.3490, dtype=torch.float64), tensor(0.2980, dtype=torch.float64), tensor(0.0899, dtype=torch.float64), tensor(0.3710, dtype=torch.float64), tensor(0.4210, dtype=torch.float64), tensor(0.1010, dtype=torch.float64), tensor(0.5010, dtype=torch.float64), tensor(0.6990, dtype=torch.float64), tensor(0.8780, dtype=torch.float64), tensor(0.2080, dtype=torch.float64), tensor(0.5530, dtype=torch.float64), tensor(0.6010, dtype=torch.float64), tensor(0.5140, dtype=torch.float64), tensor(0.4400, dtype=torch.float64), tensor(0.7330, dtype=torch.float64), tensor(0.3630, dtype=torch.float64), tensor(0.8190, dtype=torch.float64), tensor(0.4380, dtype=torch.float64), tensor(0.6840, dtype=torch.float64), tensor(0.3700, dtype=torch.float64), tensor(0.9590, dtype=torch.float64), tensor(0.6370, dtype=torch.float64), tensor(0.9080, dtype=torch.float64), tensor(0.2260, dtype=torch.float64), tensor(0.4890, dtype=torch.float64), tensor(0.5130, dtype=torch.float64), tensor(0.6960, dtype=torch.float64), tensor(0.5520, dtype=torch.float64), tensor(0.1810, dtype=torch.float64), tensor(0.3770, dtype=torch.float64), tensor(0.8100, dtype=torch.float64), tensor(0.3120, dtype=torch.float64), tensor(0.3540, dtype=torch.float64), tensor(0.9100, dtype=torch.float64), tensor(0.3720, dtype=torch.float64), tensor(0.4100, dtype=torch.float64), tensor(0.5700, dtype=torch.float64), tensor(0.4940, dtype=torch.float64), tensor(0.0591, dtype=torch.float64), tensor(0.4130, dtype=torch.float64), tensor(0.4540, dtype=torch.float64), tensor(0.5570, dtype=torch.float64), tensor(0.1300, dtype=torch.float64), tensor(0.0387, dtype=torch.float64), tensor(0.2250, dtype=torch.float64), tensor(0.2910, dtype=torch.float64), tensor(0.9230, dtype=torch.float64), tensor(0.5200, dtype=torch.float64), tensor(0.9630, dtype=torch.float64), tensor(0.5640, dtype=torch.float64), tensor(0.8130, dtype=torch.float64), tensor(0.3750, dtype=torch.float64), tensor(0.1290, dtype=torch.float64), tensor(0.3860, dtype=torch.float64), tensor(0.5340, dtype=torch.float64), tensor(0.3040, dtype=torch.float64), tensor(0.6950, dtype=torch.float64), tensor(0.6750, dtype=torch.float64), tensor(0.8730, dtype=torch.float64), tensor(0.2410, dtype=torch.float64), tensor(0.7260, dtype=torch.float64), tensor(0.7520, dtype=torch.float64), tensor(0.7620, dtype=torch.float64), tensor(0.2450, dtype=torch.float64), tensor(0.3670, dtype=torch.float64), tensor(0.8800, dtype=torch.float64), tensor(0.4600, dtype=torch.float64), tensor(0.9620, dtype=torch.float64), tensor(0.6000, dtype=torch.float64), tensor(0.2720, dtype=torch.float64), tensor(0.5380, dtype=torch.float64), tensor(0.2030, dtype=torch.float64), tensor(0.8140, dtype=torch.float64), tensor(0.7500, dtype=torch.float64), tensor(0.5870, dtype=torch.float64), tensor(0.3350, dtype=torch.float64), tensor(0.9570, dtype=torch.float64), tensor(0.3610, dtype=torch.float64), tensor(0.8800, dtype=torch.float64), tensor(0.1580, dtype=torch.float64), tensor(0.0702, dtype=torch.float64), tensor(0.2190, dtype=torch.float64), tensor(0.7720, dtype=torch.float64), tensor(0.4160, dtype=torch.float64), tensor(0.4340, dtype=torch.float64), tensor(0.8020, dtype=torch.float64), tensor(0.1480, dtype=torch.float64), tensor(0.1550, dtype=torch.float64), tensor(0.6780, dtype=torch.float64), tensor(0.5570, dtype=torch.float64), tensor(0.6570, dtype=torch.float64), tensor(0.2580, dtype=torch.float64), tensor(0.1130, dtype=torch.float64), tensor(0.7290, dtype=torch.float64), tensor(0.7020, dtype=torch.float64), tensor(0.8620, dtype=torch.float64), tensor(0.3990, dtype=torch.float64), tensor(0.7320, dtype=torch.float64), tensor(0.5700, dtype=torch.float64), tensor(0.2420, dtype=torch.float64), tensor(0.6720, dtype=torch.float64), tensor(0.3630, dtype=torch.float64), tensor(0.2350, dtype=torch.float64), tensor(0.8100, dtype=torch.float64), tensor(0.4500, dtype=torch.float64), tensor(0.9450, dtype=torch.float64), tensor(0.4770, dtype=torch.float64), tensor(0.4230, dtype=torch.float64), tensor(0.5530, dtype=torch.float64), tensor(0.8500, dtype=torch.float64), tensor(0.3990, dtype=torch.float64), tensor(0.1680, dtype=torch.float64), tensor(0.5410, dtype=torch.float64), tensor(0.0393, dtype=torch.float64), tensor(0.5880, dtype=torch.float64), tensor(0.2240, dtype=torch.float64), tensor(0.0316, dtype=torch.float64), tensor(0.7300, dtype=torch.float64), tensor(0.8150, dtype=torch.float64), tensor(0.5620, dtype=torch.float64), tensor(0.5600, dtype=torch.float64), tensor(0.6390, dtype=torch.float64), tensor(0.9320, dtype=torch.float64), tensor(0.4330, dtype=torch.float64), tensor(0.6440, dtype=torch.float64), tensor(0.4100, dtype=torch.float64), tensor(0.8460, dtype=torch.float64), tensor(0.2210, dtype=torch.float64), tensor(0.1310, dtype=torch.float64), tensor(0.0704, dtype=torch.float64), tensor(0.6740, dtype=torch.float64), tensor(0.3640, dtype=torch.float64), tensor(0.6280, dtype=torch.float64), tensor(0.5440, dtype=torch.float64), tensor(0.7830, dtype=torch.float64), tensor(0.5870, dtype=torch.float64), tensor(0.7030, dtype=torch.float64), tensor(0.4580, dtype=torch.float64), tensor(0.5110, dtype=torch.float64), tensor(0.0732, dtype=torch.float64), tensor(0.0822, dtype=torch.float64), tensor(0.2680, dtype=torch.float64), tensor(0.9170, dtype=torch.float64), tensor(0.6790, dtype=torch.float64), tensor(0.7270, dtype=torch.float64), tensor(0.3050, dtype=torch.float64), tensor(0.2690, dtype=torch.float64), tensor(0.5940, dtype=torch.float64), tensor(0.8050, dtype=torch.float64), tensor(0.8240, dtype=torch.float64), tensor(0.1980, dtype=torch.float64), tensor(0.5230, dtype=torch.float64), tensor(0.6440, dtype=torch.float64), tensor(0.5180, dtype=torch.float64), tensor(0.1360, dtype=torch.float64), tensor(0.2220, dtype=torch.float64), tensor(0.7480, dtype=torch.float64), tensor(0.2620, dtype=torch.float64), tensor(0.6810, dtype=torch.float64), tensor(0.5960, dtype=torch.float64), tensor(0.6060, dtype=torch.float64), tensor(0.9190, dtype=torch.float64), tensor(0.7340, dtype=torch.float64), tensor(0.5460, dtype=torch.float64), tensor(0.6570, dtype=torch.float64), tensor(0.4780, dtype=torch.float64), tensor(0.2850, dtype=torch.float64), tensor(0.4960, dtype=torch.float64), tensor(0.4890, dtype=torch.float64), tensor(0.3250, dtype=torch.float64), tensor(0.5800, dtype=torch.float64), tensor(0.9510, dtype=torch.float64), tensor(0.7650, dtype=torch.float64), tensor(0.1640, dtype=torch.float64), tensor(0.2250, dtype=torch.float64), tensor(0.5380, dtype=torch.float64), tensor(0.6140, dtype=torch.float64), tensor(0.2670, dtype=torch.float64), tensor(0.8680, dtype=torch.float64), tensor(0.1300, dtype=torch.float64), tensor(0.1060, dtype=torch.float64), tensor(0.5770, dtype=torch.float64), tensor(0.8420, dtype=torch.float64), tensor(0.9310, dtype=torch.float64), tensor(0.8200, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7610, dtype=torch.float64), tensor(0.3380, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.8720, dtype=torch.float64), tensor(0.5910, dtype=torch.float64), tensor(0.2790, dtype=torch.float64), tensor(0.5350, dtype=torch.float64), tensor(0.4530, dtype=torch.float64), tensor(0.2670, dtype=torch.float64), tensor(0.8020, dtype=torch.float64), tensor(0.4070, dtype=torch.float64), tensor(0.5480, dtype=torch.float64), tensor(0.6620, dtype=torch.float64), tensor(0.0468, dtype=torch.float64), tensor(0.6570, dtype=torch.float64), tensor(0.4980, dtype=torch.float64), tensor(0.3320, dtype=torch.float64), tensor(0.8050, dtype=torch.float64), tensor(0.6820, dtype=torch.float64), tensor(0.4930, dtype=torch.float64), tensor(0.4410, dtype=torch.float64), tensor(0.8620, dtype=torch.float64), tensor(0.3410, dtype=torch.float64), tensor(0.5150, dtype=torch.float64), tensor(0.7190, dtype=torch.float64), tensor(0.7940, dtype=torch.float64), tensor(0.8260, dtype=torch.float64), tensor(0.1670, dtype=torch.float64), tensor(0.6200, dtype=torch.float64), tensor(0.4620, dtype=torch.float64), tensor(0.5690, dtype=torch.float64), tensor(0.1500, dtype=torch.float64), tensor(0.6900, dtype=torch.float64), tensor(0.7110, dtype=torch.float64), tensor(0.2470, dtype=torch.float64), tensor(0.9180, dtype=torch.float64), tensor(0.5540, dtype=torch.float64), tensor(0.7890, dtype=torch.float64), tensor(0.9620, dtype=torch.float64), tensor(0.7340, dtype=torch.float64), tensor(0.1960, dtype=torch.float64), tensor(0.8650, dtype=torch.float64), tensor(0.9370, dtype=torch.float64), tensor(0.6870, dtype=torch.float64), tensor(0.6940, dtype=torch.float64), tensor(0.1870, dtype=torch.float64), tensor(0.4800, dtype=torch.float64), tensor(0.5240, dtype=torch.float64), tensor(0.7500, dtype=torch.float64), tensor(0.1650, dtype=torch.float64), tensor(0.8200, dtype=torch.float64), tensor(0.7210, dtype=torch.float64), tensor(0.0378, dtype=torch.float64), tensor(0.2860, dtype=torch.float64), tensor(0.7540, dtype=torch.float64), tensor(0.9610, dtype=torch.float64), tensor(0.8990, dtype=torch.float64), tensor(0.3080, dtype=torch.float64), tensor(0.5680, dtype=torch.float64), tensor(0.2610, dtype=torch.float64), tensor(0.6420, dtype=torch.float64), tensor(0.4820, dtype=torch.float64), tensor(0.7600, dtype=torch.float64), tensor(0.7000, dtype=torch.float64), tensor(0.5370, dtype=torch.float64), tensor(0.4510, dtype=torch.float64), tensor(0.3740, dtype=torch.float64), tensor(0.2910, dtype=torch.float64), tensor(0.7180, dtype=torch.float64), tensor(0.0862, dtype=torch.float64), tensor(0.5350, dtype=torch.float64), tensor(0.0467, dtype=torch.float64), tensor(0.3730, dtype=torch.float64), tensor(0.7910, dtype=torch.float64), tensor(0.1310, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.4840, dtype=torch.float64), tensor(0.7480, dtype=torch.float64), tensor(0.8370, dtype=torch.float64), tensor(0.4260, dtype=torch.float64), tensor(0.4980, dtype=torch.float64), tensor(0.3310, dtype=torch.float64), tensor(0.5000, dtype=torch.float64), tensor(0.4210, dtype=torch.float64), tensor(0.5990, dtype=torch.float64), tensor(0.0486, dtype=torch.float64), tensor(0.4380, dtype=torch.float64), tensor(0.8820, dtype=torch.float64), tensor(0.5130, dtype=torch.float64), tensor(0.4640, dtype=torch.float64), tensor(0.5880, dtype=torch.float64), tensor(0.0879, dtype=torch.float64), tensor(0.4870, dtype=torch.float64), tensor(0.8810, dtype=torch.float64), tensor(0.5430, dtype=torch.float64), tensor(0.2580, dtype=torch.float64), tensor(0.5990, dtype=torch.float64), tensor(0.3160, dtype=torch.float64), tensor(0.8050, dtype=torch.float64), tensor(0.6120, dtype=torch.float64), tensor(0.9100, dtype=torch.float64), tensor(0.3050, dtype=torch.float64), tensor(0.3180, dtype=torch.float64), tensor(0.0393, dtype=torch.float64), tensor(0.1580, dtype=torch.float64), tensor(0.7060, dtype=torch.float64), tensor(0.1030, dtype=torch.float64), tensor(0.3370, dtype=torch.float64), tensor(0.5360, dtype=torch.float64), tensor(0.4770, dtype=torch.float64)]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3e1c2d1ffa73f1bb062032ba813b8c7cb9a5028"
      },
      "cell_type": "code",
      "source": "from scipy.stats import spearmanr\n\nfinal_score_val , _ = spearmanr(flt_vale_labels, flt_vale_preds)\nfinal_score_ene , _ = spearmanr(flt_ene_labels, flt_ene_preds)\nfinal_score_dance, _ = spearmanr (flt_dance_labels, flt_dance_preds)\n\nfinal_score = (final_score_val+final_score_ene+final_score_dance)/3\n\nprint(\"Final score is:\", final_score)",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Final score is: 0.5736645643789718\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4ada312b41fbed4c48a0e28ced6332fde9c6dd7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}